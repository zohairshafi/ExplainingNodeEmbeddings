# ExplainingNodeEmbeddings

Node embedding methods create low-dimensional latent space representations of the nodes in a graph. These embeddings are widely used in downstream tasks such as node classification and link prediction. We answer three questions in this paper. Q1: Can we explain node embedding dimensions with "sense" features? Sense features are human-understandable graph features such as degree, clustering coefficient, PageRank, etc. We find that the answer to Q1 is yes. Additionally, by making sense of the embedding dimensions, we gain insight into the generative model of the given network. Q2: How can we modify existing node embedding algorithms to produce embeddings that are more easily explained with sense features? We introduce a new framework called XM (short for eXplain eMbedding) to answer this question. Our method, XM, produces robust and explainable node embeddings on both synthetic and real-world graphs, achieving downstream task performances comparable to the state-of-the-art. Q3: Can we use XM to select the optimal number of dimensions for node embedding? We find that the answer to Q3 is yes and present a task-independent model selection approach that uses Minimum Description Length. 

Code for SDNE and LINE are adopted from https://github.com/shenweichen/GraphEmbedding