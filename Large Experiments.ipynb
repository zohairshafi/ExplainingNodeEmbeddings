{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e23f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a3e83b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/pubmed.pkl', 'rb') as file: \n",
    "    graph = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e284fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4998501d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Personalized Page Rank...                     \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19717it [10:41, 30.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Katz Centrality...                            \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohairshafi/miniforge3/lib/python3.10/site-packages/networkx/algorithms/centrality/katz.py:325: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(G, nodelist=nodelist, weight=weight).todense().T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing Features Between 0 And 1...                   \r",
      "Done                                                      \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Max\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 18:37:43.829551: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-01-11 18:37:43.829671: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 99ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 18:37:44.055194: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-01-11 18:37:44.084872: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "2/2 [==============================] - 0s 139ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 18:37:45.198547: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-11 18:37:46.129235: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-11 18:37:50.212241: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "5s - loss:  214.3038 - 2nd_loss:  214.1941 - 1st_loss:  0.0609 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 2/100\n",
      "3s - loss:  172.6321 - 2nd_loss:  170.6372 - 1st_loss:  1.9474 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 3/100\n",
      "3s - loss:  117.8922 - 2nd_loss:  113.0795 - 1st_loss:  4.7465 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 4/100\n",
      "3s - loss:  88.4219 - 2nd_loss:  84.2189 - 1st_loss:  4.1279 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 5/100\n",
      "3s - loss:  77.0123 - 2nd_loss:  73.3802 - 1st_loss:  3.5558 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 6/100\n",
      "3s - loss:  72.5408 - 2nd_loss:  69.4113 - 1st_loss:  3.0554 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 7/100\n",
      "3s - loss:  70.3458 - 2nd_loss:  67.5856 - 1st_loss:  2.6889 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 8/100\n",
      "3s - loss:  69.2218 - 2nd_loss:  66.7743 - 1st_loss:  2.3788 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 9/100\n",
      "3s - loss:  68.2685 - 2nd_loss:  66.0512 - 1st_loss:  2.1508 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 10/100\n",
      "3s - loss:  67.7476 - 2nd_loss:  65.7349 - 1st_loss:  1.9481 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 11/100\n",
      "3s - loss:  67.2819 - 2nd_loss:  65.4424 - 1st_loss:  1.7763 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 12/100\n",
      "3s - loss:  66.7358 - 2nd_loss:  65.0426 - 1st_loss:  1.6313 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 13/100\n",
      "3s - loss:  66.3361 - 2nd_loss:  64.7714 - 1st_loss:  1.5040 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 14/100\n",
      "3s - loss:  66.0269 - 2nd_loss:  64.5730 - 1st_loss:  1.3942 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 15/100\n",
      "3s - loss:  65.7072 - 2nd_loss:  64.3533 - 1st_loss:  1.2952 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 16/100\n",
      "3s - loss:  65.4367 - 2nd_loss:  64.1697 - 1st_loss:  1.2092 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 17/100\n",
      "3s - loss:  65.2494 - 2nd_loss:  64.0619 - 1st_loss:  1.1305 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 18/100\n",
      "3s - loss:  65.0135 - 2nd_loss:  63.8943 - 1st_loss:  1.0629 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 19/100\n",
      "3s - loss:  64.8530 - 2nd_loss:  63.7975 - 1st_loss:  1.0000 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 20/100\n",
      "3s - loss:  64.6984 - 2nd_loss:  63.6967 - 1st_loss:  0.9467 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 21/100\n",
      "3s - loss:  64.4968 - 2nd_loss:  63.5449 - 1st_loss:  0.8976 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 22/100\n",
      "3s - loss:  64.3575 - 2nd_loss:  63.4506 - 1st_loss:  0.8532 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 23/100\n",
      "3s - loss:  64.2368 - 2nd_loss:  63.3697 - 1st_loss:  0.8140 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 24/100\n",
      "3s - loss:  64.1377 - 2nd_loss:  63.3087 - 1st_loss:  0.7765 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 25/100\n",
      "3s - loss:  64.0202 - 2nd_loss:  63.2244 - 1st_loss:  0.7438 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 26/100\n",
      "3s - loss:  63.9050 - 2nd_loss:  63.1422 - 1st_loss:  0.7114 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 27/100\n",
      "3s - loss:  63.7696 - 2nd_loss:  63.0367 - 1st_loss:  0.6819 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 28/100\n",
      "3s - loss:  63.6497 - 2nd_loss:  62.9458 - 1st_loss:  0.6534 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 29/100\n",
      "3s - loss:  63.5097 - 2nd_loss:  62.8333 - 1st_loss:  0.6265 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 30/100\n",
      "3s - loss:  63.3843 - 2nd_loss:  62.7343 - 1st_loss:  0.6006 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 31/100\n",
      "3s - loss:  63.3201 - 2nd_loss:  62.6951 - 1st_loss:  0.5760 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 32/100\n",
      "3s - loss:  63.2067 - 2nd_loss:  62.6055 - 1st_loss:  0.5527 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 33/100\n",
      "3s - loss:  63.1203 - 2nd_loss:  62.5416 - 1st_loss:  0.5307 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 34/100\n",
      "3s - loss:  63.0252 - 2nd_loss:  62.4673 - 1st_loss:  0.5103 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 35/100\n",
      "3s - loss:  62.9456 - 2nd_loss:  62.4076 - 1st_loss:  0.4909 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 36/100\n",
      "3s - loss:  62.8231 - 2nd_loss:  62.3034 - 1st_loss:  0.4730 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 37/100\n",
      "3s - loss:  62.7145 - 2nd_loss:  62.2126 - 1st_loss:  0.4558 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 38/100\n",
      "3s - loss:  62.6331 - 2nd_loss:  62.1477 - 1st_loss:  0.4396 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 39/100\n",
      "3s - loss:  62.5482 - 2nd_loss:  62.0787 - 1st_loss:  0.4242 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 40/100\n",
      "3s - loss:  62.5070 - 2nd_loss:  62.0521 - 1st_loss:  0.4099 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 41/100\n",
      "3s - loss:  62.4282 - 2nd_loss:  61.9878 - 1st_loss:  0.3959 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 42/100\n",
      "3s - loss:  62.3614 - 2nd_loss:  61.9341 - 1st_loss:  0.3832 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 43/100\n",
      "3s - loss:  62.2743 - 2nd_loss:  61.8596 - 1st_loss:  0.3709 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 44/100\n",
      "3s - loss:  62.1942 - 2nd_loss:  61.7908 - 1st_loss:  0.3600 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 45/100\n",
      "3s - loss:  62.1316 - 2nd_loss:  61.7400 - 1st_loss:  0.3486 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 46/100\n",
      "3s - loss:  62.1038 - 2nd_loss:  61.7222 - 1st_loss:  0.3390 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 47/100\n",
      "3s - loss:  62.0648 - 2nd_loss:  61.6938 - 1st_loss:  0.3288 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 48/100\n",
      "3s - loss:  61.9880 - 2nd_loss:  61.6262 - 1st_loss:  0.3199 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 49/100\n",
      "3s - loss:  61.9454 - 2nd_loss:  61.5929 - 1st_loss:  0.3111 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 50/100\n",
      "3s - loss:  61.8930 - 2nd_loss:  61.5490 - 1st_loss:  0.3030 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 51/100\n",
      "3s - loss:  61.8426 - 2nd_loss:  61.5071 - 1st_loss:  0.2949 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 52/100\n",
      "3s - loss:  61.7371 - 2nd_loss:  61.4094 - 1st_loss:  0.2875 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 53/100\n",
      "3s - loss:  61.6975 - 2nd_loss:  61.3775 - 1st_loss:  0.2801 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 54/100\n",
      "3s - loss:  61.6648 - 2nd_loss:  61.3520 - 1st_loss:  0.2733 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 55/100\n",
      "3s - loss:  61.5885 - 2nd_loss:  61.2828 - 1st_loss:  0.2665 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 56/100\n",
      "3s - loss:  61.5211 - 2nd_loss:  61.2219 - 1st_loss:  0.2603 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 57/100\n",
      "3s - loss:  61.4713 - 2nd_loss:  61.1787 - 1st_loss:  0.2541 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 58/100\n",
      "3s - loss:  61.4605 - 2nd_loss:  61.1740 - 1st_loss:  0.2484 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 59/100\n",
      "3s - loss:  61.4303 - 2nd_loss:  61.1498 - 1st_loss:  0.2427 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 60/100\n",
      "3s - loss:  61.4054 - 2nd_loss:  61.1304 - 1st_loss:  0.2376 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 61/100\n",
      "3s - loss:  61.3775 - 2nd_loss:  61.1080 - 1st_loss:  0.2324 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 62/100\n",
      "3s - loss:  61.3361 - 2nd_loss:  61.0717 - 1st_loss:  0.2277 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 63/100\n",
      "3s - loss:  61.3022 - 2nd_loss:  61.0430 - 1st_loss:  0.2228 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 64/100\n",
      "3s - loss:  61.2950 - 2nd_loss:  61.0404 - 1st_loss:  0.2185 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 65/100\n",
      "3s - loss:  61.2782 - 2nd_loss:  61.0284 - 1st_loss:  0.2140 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 66/100\n",
      "3s - loss:  61.2667 - 2nd_loss:  61.0213 - 1st_loss:  0.2100 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 67/100\n",
      "3s - loss:  61.2588 - 2nd_loss:  61.0178 - 1st_loss:  0.2058 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 68/100\n",
      "3s - loss:  61.2313 - 2nd_loss:  60.9943 - 1st_loss:  0.2022 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "3s - loss:  61.2043 - 2nd_loss:  60.9715 - 1st_loss:  0.1983 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 70/100\n",
      "3s - loss:  61.1981 - 2nd_loss:  60.9692 - 1st_loss:  0.1947 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 71/100\n",
      "3s - loss:  61.1699 - 2nd_loss:  60.9449 - 1st_loss:  0.1911 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 72/100\n",
      "3s - loss:  61.1615 - 2nd_loss:  60.9401 - 1st_loss:  0.1878 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 73/100\n",
      "3s - loss:  61.1383 - 2nd_loss:  60.9206 - 1st_loss:  0.1843 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 74/100\n",
      "3s - loss:  61.1295 - 2nd_loss:  60.9153 - 1st_loss:  0.1811 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 75/100\n",
      "3s - loss:  61.1037 - 2nd_loss:  60.8931 - 1st_loss:  0.1778 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 76/100\n",
      "3s - loss:  61.0942 - 2nd_loss:  60.8867 - 1st_loss:  0.1749 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 77/100\n",
      "3s - loss:  61.0892 - 2nd_loss:  60.8851 - 1st_loss:  0.1718 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 78/100\n",
      "3s - loss:  61.0777 - 2nd_loss:  60.8765 - 1st_loss:  0.1691 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 79/100\n",
      "3s - loss:  61.0756 - 2nd_loss:  60.8776 - 1st_loss:  0.1662 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 80/100\n",
      "3s - loss:  61.0760 - 2nd_loss:  60.8806 - 1st_loss:  0.1637 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 81/100\n",
      "3s - loss:  61.0664 - 2nd_loss:  60.8740 - 1st_loss:  0.1610 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 82/100\n",
      "3s - loss:  61.0559 - 2nd_loss:  60.8661 - 1st_loss:  0.1586 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 83/100\n",
      "3s - loss:  61.0444 - 2nd_loss:  60.8574 - 1st_loss:  0.1560 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 84/100\n",
      "3s - loss:  61.0385 - 2nd_loss:  60.8541 - 1st_loss:  0.1537 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 85/100\n",
      "3s - loss:  61.0181 - 2nd_loss:  60.8365 - 1st_loss:  0.1512 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 86/100\n",
      "3s - loss:  61.0075 - 2nd_loss:  60.8283 - 1st_loss:  0.1489 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 87/100\n",
      "3s - loss:  60.9998 - 2nd_loss:  60.8233 - 1st_loss:  0.1465 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 88/100\n",
      "3s - loss:  61.0075 - 2nd_loss:  60.8333 - 1st_loss:  0.1444 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 89/100\n",
      "3s - loss:  60.9897 - 2nd_loss:  60.8179 - 1st_loss:  0.1421 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 90/100\n",
      "3s - loss:  60.9466 - 2nd_loss:  60.7768 - 1st_loss:  0.1403 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 91/100\n",
      "3s - loss:  60.9179 - 2nd_loss:  60.7506 - 1st_loss:  0.1379 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 92/100\n",
      "3s - loss:  60.8811 - 2nd_loss:  60.7158 - 1st_loss:  0.1361 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 93/100\n",
      "3s - loss:  60.8596 - 2nd_loss:  60.6967 - 1st_loss:  0.1340 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 94/100\n",
      "3s - loss:  60.7864 - 2nd_loss:  60.6256 - 1st_loss:  0.1320 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 95/100\n",
      "3s - loss:  60.7802 - 2nd_loss:  60.6218 - 1st_loss:  0.1299 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 96/100\n",
      "3s - loss:  60.7703 - 2nd_loss:  60.6140 - 1st_loss:  0.1280 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 97/100\n",
      "3s - loss:  60.7590 - 2nd_loss:  60.6049 - 1st_loss:  0.1259 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 98/100\n",
      "3s - loss:  60.7393 - 2nd_loss:  60.5871 - 1st_loss:  0.1242 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 99/100\n",
      "3s - loss:  60.7334 - 2nd_loss:  60.5833 - 1st_loss:  0.1223 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "Epoch 100/100\n",
      "3s - loss:  60.7195 - 2nd_loss:  60.5711 - 1st_loss:  0.1207 - ortho_loss :  0.0000 - sparse_loss :  0.0000\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 18:43:15.114289: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 18:43:16.354676: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-11 18:43:16.936964: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-01-11 18:43:20.998382: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "5s - loss:  4926.6935 - 2nd_loss:  60.7219 - 1st_loss:  1.6128 - ortho_loss :  2431.0929 - sparse_loss :  2433.2384\n",
      "Epoch 2/200\n",
      "3s - loss:  3061.0865 - 2nd_loss:  62.6511 - 1st_loss:  2.9585 - ortho_loss :  1248.4230 - sparse_loss :  1747.0233\n",
      "Epoch 3/200\n",
      "3s - loss:  2257.4667 - 2nd_loss:  65.1503 - 1st_loss:  4.7753 - ortho_loss :  795.9141 - sparse_loss :  1391.5929\n",
      "Epoch 4/200\n",
      "3s - loss:  1817.1407 - 2nd_loss:  65.9483 - 1st_loss:  6.8487 - ortho_loss :  569.5246 - sparse_loss :  1174.7821\n",
      "Epoch 5/200\n",
      "3s - loss:  1537.7627 - 2nd_loss:  65.7747 - 1st_loss:  9.1536 - ortho_loss :  436.4413 - sparse_loss :  1026.3536\n",
      "Epoch 6/200\n",
      "3s - loss:  1332.2102 - 2nd_loss:  65.3804 - 1st_loss:  11.7363 - ortho_loss :  344.7327 - sparse_loss :  910.3188\n",
      "Epoch 7/200\n",
      "3s - loss:  1170.5989 - 2nd_loss:  65.0221 - 1st_loss:  14.5035 - ortho_loss :  276.6566 - sparse_loss :  814.3726\n",
      "Epoch 8/200\n",
      "3s - loss:  1049.6441 - 2nd_loss:  64.6827 - 1st_loss:  17.3415 - ortho_loss :  228.3695 - sparse_loss :  739.2043\n",
      "Epoch 9/200\n",
      "3s - loss:  955.4681 - 2nd_loss:  64.3865 - 1st_loss:  20.2196 - ortho_loss :  192.5752 - sparse_loss :  678.2390\n",
      "Epoch 10/200\n",
      "3s - loss:  878.7483 - 2nd_loss:  64.1338 - 1st_loss:  23.0775 - ortho_loss :  164.6708 - sparse_loss :  626.8167\n",
      "Epoch 11/200\n",
      "3s - loss:  815.6578 - 2nd_loss:  63.8347 - 1st_loss:  25.8963 - ortho_loss :  142.6583 - sparse_loss :  583.2175\n",
      "Epoch 12/200\n",
      "3s - loss:  763.2896 - 2nd_loss:  63.5774 - 1st_loss:  28.6001 - ortho_loss :  125.0784 - sparse_loss :  545.9814\n",
      "Epoch 13/200\n",
      "3s - loss:  719.1146 - 2nd_loss:  63.3115 - 1st_loss:  31.2066 - ortho_loss :  110.7910 - sparse_loss :  513.7517\n",
      "Epoch 14/200\n",
      "3s - loss:  681.3521 - 2nd_loss:  63.0603 - 1st_loss:  33.6425 - ortho_loss :  99.0066 - sparse_loss :  485.5877\n",
      "Epoch 15/200\n",
      "3s - loss:  648.2597 - 2nd_loss:  62.8232 - 1st_loss:  35.9615 - ortho_loss :  89.0100 - sparse_loss :  460.4089\n",
      "Epoch 16/200\n",
      "3s - loss:  618.9913 - 2nd_loss:  62.5927 - 1st_loss:  38.1102 - ortho_loss :  80.4535 - sparse_loss :  437.7778\n",
      "Epoch 17/200\n",
      "3s - loss:  593.0870 - 2nd_loss:  62.3522 - 1st_loss:  40.1427 - ortho_loss :  73.1075 - sparse_loss :  417.4264\n",
      "Epoch 18/200\n",
      "3s - loss:  570.2201 - 2nd_loss:  62.1398 - 1st_loss:  42.0091 - ortho_loss :  66.8102 - sparse_loss :  399.2021\n",
      "Epoch 19/200\n",
      "3s - loss:  550.0311 - 2nd_loss:  61.9303 - 1st_loss:  43.7788 - ortho_loss :  61.3984 - sparse_loss :  382.8638\n",
      "Epoch 20/200\n",
      "3s - loss:  531.9031 - 2nd_loss:  61.7187 - 1st_loss:  45.4162 - ortho_loss :  56.6784 - sparse_loss :  368.0292\n",
      "Epoch 21/200\n",
      "3s - loss:  515.6348 - 2nd_loss:  61.4149 - 1st_loss:  46.9827 - ortho_loss :  52.5739 - sparse_loss :  354.6020\n",
      "Epoch 22/200\n",
      "3s - loss:  500.9500 - 2nd_loss:  61.1944 - 1st_loss:  48.4340 - ortho_loss :  48.9507 - sparse_loss :  342.3090\n",
      "Epoch 23/200\n",
      "3s - loss:  487.5279 - 2nd_loss:  61.0310 - 1st_loss:  49.8475 - ortho_loss :  45.6991 - sparse_loss :  330.8878\n",
      "Epoch 24/200\n",
      "3s - loss:  475.1221 - 2nd_loss:  60.8834 - 1st_loss:  51.1569 - ortho_loss :  42.7685 - sparse_loss :  320.2501\n",
      "Epoch 25/200\n",
      "3s - loss:  463.6608 - 2nd_loss:  60.7525 - 1st_loss:  52.4349 - ortho_loss :  40.1133 - sparse_loss :  310.2964\n",
      "Epoch 26/200\n",
      "3s - loss:  453.0365 - 2nd_loss:  60.6661 - 1st_loss:  53.6118 - ortho_loss :  37.7055 - sparse_loss :  300.9889\n",
      "Epoch 27/200\n",
      "3s - loss:  443.1048 - 2nd_loss:  60.4986 - 1st_loss:  54.7885 - ortho_loss :  35.5107 - sparse_loss :  292.2423\n",
      "Epoch 28/200\n",
      "3s - loss:  433.9008 - 2nd_loss:  60.4110 - 1st_loss:  55.8420 - ortho_loss :  33.5174 - sparse_loss :  284.0653\n",
      "Epoch 29/200\n",
      "3s - loss:  425.3549 - 2nd_loss:  60.3096 - 1st_loss:  56.9043 - ortho_loss :  31.6964 - sparse_loss :  276.3792\n",
      "Epoch 30/200\n",
      "3s - loss:  417.3756 - 2nd_loss:  60.2191 - 1st_loss:  57.8656 - ortho_loss :  30.0389 - sparse_loss :  269.1863\n",
      "Epoch 31/200\n",
      "3s - loss:  409.8761 - 2nd_loss:  60.0858 - 1st_loss:  58.8172 - ortho_loss :  28.5151 - sparse_loss :  262.3918\n",
      "Epoch 32/200\n",
      "3s - loss:  402.8559 - 2nd_loss:  60.0025 - 1st_loss:  59.6981 - ortho_loss :  27.1136 - sparse_loss :  255.9753\n",
      "Epoch 33/200\n",
      "3s - loss:  396.2230 - 2nd_loss:  59.8556 - 1st_loss:  60.5495 - ortho_loss :  25.8259 - sparse_loss :  249.9252\n",
      "Epoch 34/200\n",
      "3s - loss:  390.0387 - 2nd_loss:  59.7594 - 1st_loss:  61.3529 - ortho_loss :  24.6411 - sparse_loss :  244.2183\n",
      "Epoch 35/200\n",
      "3s - loss:  384.2216 - 2nd_loss:  59.6697 - 1st_loss:  62.1169 - ortho_loss :  23.5460 - sparse_loss :  238.8217\n",
      "Epoch 36/200\n",
      "3s - loss:  378.8368 - 2nd_loss:  59.6238 - 1st_loss:  62.8399 - ortho_loss :  22.5424 - sparse_loss :  233.7631\n",
      "Epoch 37/200\n",
      "3s - loss:  373.8384 - 2nd_loss:  59.5643 - 1st_loss:  63.5270 - ortho_loss :  21.6274 - sparse_loss :  229.0521\n",
      "Epoch 38/200\n",
      "3s - loss:  369.2253 - 2nd_loss:  59.4881 - 1st_loss:  64.1778 - ortho_loss :  20.7977 - sparse_loss :  224.6937\n",
      "Epoch 39/200\n",
      "3s - loss:  365.0033 - 2nd_loss:  59.4236 - 1st_loss:  64.8016 - ortho_loss :  20.0458 - sparse_loss :  220.6642\n",
      "Epoch 40/200\n",
      "3s - loss:  361.1375 - 2nd_loss:  59.3614 - 1st_loss:  65.3929 - ortho_loss :  19.3667 - sparse_loss :  216.9483\n",
      "Epoch 41/200\n",
      "3s - loss:  357.4883 - 2nd_loss:  59.2349 - 1st_loss:  65.9595 - ortho_loss :  18.7453 - sparse_loss :  213.4802\n",
      "Epoch 42/200\n",
      "3s - loss:  354.0279 - 2nd_loss:  59.1061 - 1st_loss:  66.4938 - ortho_loss :  18.1672 - sparse_loss :  210.1923\n",
      "Epoch 43/200\n",
      "3s - loss:  350.7978 - 2nd_loss:  59.0329 - 1st_loss:  67.0117 - ortho_loss :  17.6260 - sparse_loss :  207.0585\n",
      "Epoch 44/200\n",
      "3s - loss:  347.6659 - 2nd_loss:  58.9481 - 1st_loss:  67.5064 - ortho_loss :  17.1120 - sparse_loss :  204.0306\n",
      "Epoch 45/200\n",
      "3s - loss:  344.6392 - 2nd_loss:  58.8659 - 1st_loss:  67.9979 - ortho_loss :  16.6198 - sparse_loss :  201.0865\n",
      "Epoch 46/200\n",
      "3s - loss:  341.6613 - 2nd_loss:  58.7475 - 1st_loss:  68.4547 - ortho_loss :  16.1521 - sparse_loss :  198.2378\n",
      "Epoch 47/200\n",
      "3s - loss:  338.8421 - 2nd_loss:  58.6967 - 1st_loss:  68.9139 - ortho_loss :  15.7023 - sparse_loss :  195.4600\n",
      "Epoch 48/200\n",
      "3s - loss:  336.0752 - 2nd_loss:  58.6285 - 1st_loss:  69.3301 - ortho_loss :  15.2750 - sparse_loss :  192.7722\n",
      "Epoch 49/200\n",
      "3s - loss:  333.3596 - 2nd_loss:  58.5317 - 1st_loss:  69.7560 - ortho_loss :  14.8617 - sparse_loss :  190.1406\n",
      "Epoch 50/200\n",
      "3s - loss:  330.7242 - 2nd_loss:  58.4557 - 1st_loss:  70.1304 - ortho_loss :  14.4701 - sparse_loss :  187.5983\n",
      "Epoch 51/200\n",
      "3s - loss:  328.1914 - 2nd_loss:  58.4145 - 1st_loss:  70.5151 - ortho_loss :  14.0897 - sparse_loss :  185.1023\n",
      "Epoch 52/200\n",
      "3s - loss:  325.7055 - 2nd_loss:  58.3662 - 1st_loss:  70.8538 - ortho_loss :  13.7289 - sparse_loss :  182.6868\n",
      "Epoch 53/200\n",
      "3s - loss:  323.2046 - 2nd_loss:  58.2469 - 1st_loss:  71.2007 - ortho_loss :  13.3770 - sparse_loss :  180.3100\n",
      "Epoch 54/200\n",
      "3s - loss:  320.8081 - 2nd_loss:  58.1852 - 1st_loss:  71.5062 - ortho_loss :  13.0424 - sparse_loss :  178.0043\n",
      "Epoch 55/200\n",
      "3s - loss:  318.4671 - 2nd_loss:  58.1311 - 1st_loss:  71.8126 - ortho_loss :  12.7161 - sparse_loss :  175.7372\n",
      "Epoch 56/200\n",
      "3s - loss:  316.1617 - 2nd_loss:  58.0700 - 1st_loss:  72.0757 - ortho_loss :  12.4065 - sparse_loss :  173.5393\n",
      "Epoch 57/200\n",
      "3s - loss:  313.9028 - 2nd_loss:  58.0151 - 1st_loss:  72.3466 - ortho_loss :  12.1022 - sparse_loss :  171.3685\n",
      "Epoch 58/200\n",
      "3s - loss:  311.6495 - 2nd_loss:  57.9283 - 1st_loss:  72.5678 - ortho_loss :  11.8149 - sparse_loss :  169.2682\n",
      "Epoch 59/200\n",
      "3s - loss:  309.4507 - 2nd_loss:  57.8608 - 1st_loss:  72.8092 - ortho_loss :  11.5293 - sparse_loss :  167.1810\n",
      "Epoch 60/200\n",
      "3s - loss:  307.3166 - 2nd_loss:  57.8216 - 1st_loss:  72.9895 - ortho_loss :  11.2632 - sparse_loss :  165.1718\n",
      "Epoch 61/200\n",
      "3s - loss:  305.1971 - 2nd_loss:  57.7731 - 1st_loss:  73.2208 - ortho_loss :  10.9899 - sparse_loss :  163.1428\n",
      "Epoch 62/200\n",
      "3s - loss:  303.0914 - 2nd_loss:  57.6860 - 1st_loss:  73.3364 - ortho_loss :  10.7520 - sparse_loss :  161.2463\n",
      "Epoch 63/200\n",
      "3s - loss:  300.9609 - 2nd_loss:  57.5838 - 1st_loss:  73.5435 - ortho_loss :  10.4867 - sparse_loss :  159.2762\n",
      "Epoch 64/200\n",
      "3s - loss:  298.8994 - 2nd_loss:  57.5003 - 1st_loss:  73.6171 - ortho_loss :  10.2612 - sparse_loss :  157.4501\n",
      "Epoch 65/200\n",
      "3s - loss:  296.8728 - 2nd_loss:  57.4448 - 1st_loss:  73.7809 - ortho_loss :  10.0154 - sparse_loss :  155.5608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/200\n",
      "3s - loss:  294.8731 - 2nd_loss:  57.3787 - 1st_loss:  73.8349 - ortho_loss :  9.7997 - sparse_loss :  153.7889\n",
      "Epoch 67/200\n",
      "3s - loss:  292.9228 - 2nd_loss:  57.3559 - 1st_loss:  73.9395 - ortho_loss :  9.5731 - sparse_loss :  151.9835\n",
      "Epoch 68/200\n",
      "3s - loss:  290.9946 - 2nd_loss:  57.3214 - 1st_loss:  73.9781 - ortho_loss :  9.3658 - sparse_loss :  150.2583\n",
      "Epoch 69/200\n",
      "3s - loss:  289.1585 - 2nd_loss:  57.3010 - 1st_loss:  74.0330 - ortho_loss :  9.1627 - sparse_loss :  148.5908\n",
      "Epoch 70/200\n",
      "3s - loss:  287.4265 - 2nd_loss:  57.2159 - 1st_loss:  74.0272 - ortho_loss :  8.9900 - sparse_loss :  147.1223\n",
      "Epoch 71/200\n",
      "3s - loss:  285.7145 - 2nd_loss:  57.1041 - 1st_loss:  74.0382 - ortho_loss :  8.8185 - sparse_loss :  145.6826\n",
      "Epoch 72/200\n",
      "3s - loss:  284.1176 - 2nd_loss:  57.0915 - 1st_loss:  74.0008 - ortho_loss :  8.6600 - sparse_loss :  144.2941\n",
      "Epoch 73/200\n",
      "3s - loss:  282.5181 - 2nd_loss:  57.0693 - 1st_loss:  73.9889 - ortho_loss :  8.4951 - sparse_loss :  142.8937\n",
      "Epoch 74/200\n",
      "3s - loss:  280.8804 - 2nd_loss:  56.9894 - 1st_loss:  73.9279 - ortho_loss :  8.3437 - sparse_loss :  141.5481\n",
      "Epoch 75/200\n",
      "3s - loss:  279.2375 - 2nd_loss:  56.9116 - 1st_loss:  73.8845 - ortho_loss :  8.1868 - sparse_loss :  140.1832\n",
      "Epoch 76/200\n",
      "3s - loss:  277.6123 - 2nd_loss:  56.8388 - 1st_loss:  73.8160 - ortho_loss :  8.0391 - sparse_loss :  138.8469\n",
      "Epoch 77/200\n",
      "3s - loss:  275.9982 - 2nd_loss:  56.7929 - 1st_loss:  73.7496 - ortho_loss :  7.8859 - sparse_loss :  137.4983\n",
      "Epoch 78/200\n",
      "3s - loss:  274.4277 - 2nd_loss:  56.7580 - 1st_loss:  73.6498 - ortho_loss :  7.7484 - sparse_loss :  136.1998\n",
      "Epoch 79/200\n",
      "3s - loss:  272.8240 - 2nd_loss:  56.7154 - 1st_loss:  73.5814 - ortho_loss :  7.5950 - sparse_loss :  134.8604\n",
      "Epoch 80/200\n",
      "3s - loss:  271.2718 - 2nd_loss:  56.6744 - 1st_loss:  73.4310 - ortho_loss :  7.4676 - sparse_loss :  133.6270\n",
      "Epoch 81/200\n",
      "3s - loss:  269.7228 - 2nd_loss:  56.6276 - 1st_loss:  73.3300 - ortho_loss :  7.3257 - sparse_loss :  132.3676\n",
      "Epoch 82/200\n",
      "3s - loss:  268.2490 - 2nd_loss:  56.6057 - 1st_loss:  73.1734 - ortho_loss :  7.2021 - sparse_loss :  131.1957\n",
      "Epoch 83/200\n",
      "3s - loss:  266.8259 - 2nd_loss:  56.5802 - 1st_loss:  73.0237 - ortho_loss :  7.0814 - sparse_loss :  130.0685\n",
      "Epoch 84/200\n",
      "3s - loss:  265.4666 - 2nd_loss:  56.5551 - 1st_loss:  72.8393 - ortho_loss :  6.9737 - sparse_loss :  129.0262\n",
      "Epoch 85/200\n",
      "3s - loss:  264.2205 - 2nd_loss:  56.5311 - 1st_loss:  72.6730 - ortho_loss :  6.8713 - sparse_loss :  128.0726\n",
      "Epoch 86/200\n",
      "3s - loss:  263.0513 - 2nd_loss:  56.5236 - 1st_loss:  72.4449 - ortho_loss :  6.7839 - sparse_loss :  127.2263\n",
      "Epoch 87/200\n",
      "3s - loss:  261.9233 - 2nd_loss:  56.5139 - 1st_loss:  72.2287 - ortho_loss :  6.7016 - sparse_loss :  126.4064\n",
      "Epoch 88/200\n",
      "3s - loss:  260.7614 - 2nd_loss:  56.4716 - 1st_loss:  72.0202 - ortho_loss :  6.6139 - sparse_loss :  125.5829\n",
      "Epoch 89/200\n",
      "3s - loss:  259.6617 - 2nd_loss:  56.4051 - 1st_loss:  71.7778 - ortho_loss :  6.5494 - sparse_loss :  124.8564\n",
      "Epoch 90/200\n",
      "3s - loss:  258.4393 - 2nd_loss:  56.2668 - 1st_loss:  71.5797 - ortho_loss :  6.4580 - sparse_loss :  124.0617\n",
      "Epoch 91/200\n",
      "3s - loss:  257.3768 - 2nd_loss:  56.2484 - 1st_loss:  71.3442 - ortho_loss :  6.3858 - sparse_loss :  123.3251\n",
      "Epoch 92/200\n",
      "3s - loss:  256.2144 - 2nd_loss:  56.1755 - 1st_loss:  71.0737 - ortho_loss :  6.3193 - sparse_loss :  122.5725\n",
      "Epoch 93/200\n",
      "3s - loss:  255.0910 - 2nd_loss:  56.1823 - 1st_loss:  70.8378 - ortho_loss :  6.2283 - sparse_loss :  121.7691\n",
      "Epoch 94/200\n",
      "3s - loss:  253.9450 - 2nd_loss:  56.1083 - 1st_loss:  70.5749 - ortho_loss :  6.1631 - sparse_loss :  121.0250\n",
      "Epoch 95/200\n",
      "3s - loss:  252.8829 - 2nd_loss:  56.0728 - 1st_loss:  70.3232 - ortho_loss :  6.0876 - sparse_loss :  120.3255\n",
      "Epoch 96/200\n",
      "3s - loss:  251.8818 - 2nd_loss:  55.9961 - 1st_loss:  70.0494 - ortho_loss :  6.0326 - sparse_loss :  119.7296\n",
      "Epoch 97/200\n",
      "3s - loss:  250.9516 - 2nd_loss:  55.9869 - 1st_loss:  69.7735 - ortho_loss :  5.9738 - sparse_loss :  119.1432\n",
      "Epoch 98/200\n",
      "3s - loss:  250.0293 - 2nd_loss:  55.9720 - 1st_loss:  69.5033 - ortho_loss :  5.9174 - sparse_loss :  118.5622\n",
      "Epoch 99/200\n",
      "3s - loss:  249.1276 - 2nd_loss:  55.9575 - 1st_loss:  69.2115 - ortho_loss :  5.8663 - sparse_loss :  118.0177\n",
      "Epoch 100/200\n",
      "3s - loss:  248.2398 - 2nd_loss:  55.9349 - 1st_loss:  68.9508 - ortho_loss :  5.8129 - sparse_loss :  117.4666\n",
      "Epoch 101/200\n",
      "3s - loss:  247.3150 - 2nd_loss:  55.8514 - 1st_loss:  68.6714 - ortho_loss :  5.7643 - sparse_loss :  116.9531\n",
      "Epoch 102/200\n",
      "3s - loss:  246.4879 - 2nd_loss:  55.7957 - 1st_loss:  68.4073 - ortho_loss :  5.7199 - sparse_loss :  116.4901\n",
      "Epoch 103/200\n",
      "3s - loss:  245.6769 - 2nd_loss:  55.7623 - 1st_loss:  68.0991 - ortho_loss :  5.6820 - sparse_loss :  116.0585\n",
      "Epoch 104/200\n",
      "3s - loss:  244.9401 - 2nd_loss:  55.7513 - 1st_loss:  67.8188 - ortho_loss :  5.6415 - sparse_loss :  115.6533\n",
      "Epoch 105/200\n",
      "3s - loss:  244.2460 - 2nd_loss:  55.7210 - 1st_loss:  67.5355 - ortho_loss :  5.6074 - sparse_loss :  115.3068\n",
      "Epoch 106/200\n",
      "3s - loss:  243.5963 - 2nd_loss:  55.6813 - 1st_loss:  67.2338 - ortho_loss :  5.5823 - sparse_loss :  115.0234\n",
      "Epoch 107/200\n",
      "3s - loss:  242.9251 - 2nd_loss:  55.6304 - 1st_loss:  66.9686 - ortho_loss :  5.5499 - sparse_loss :  114.7006\n",
      "Epoch 108/200\n",
      "3s - loss:  242.2847 - 2nd_loss:  55.6113 - 1st_loss:  66.6877 - ortho_loss :  5.5222 - sparse_loss :  114.3876\n",
      "Epoch 109/200\n",
      "3s - loss:  241.6356 - 2nd_loss:  55.5993 - 1st_loss:  66.4505 - ortho_loss :  5.4858 - sparse_loss :  114.0240\n",
      "Epoch 110/200\n",
      "3s - loss:  240.9737 - 2nd_loss:  55.5791 - 1st_loss:  66.1727 - ortho_loss :  5.4569 - sparse_loss :  113.6887\n",
      "Epoch 111/200\n",
      "3s - loss:  240.2938 - 2nd_loss:  55.5624 - 1st_loss:  65.9557 - ortho_loss :  5.4160 - sparse_loss :  113.2834\n",
      "Epoch 112/200\n",
      "3s - loss:  239.5594 - 2nd_loss:  55.4990 - 1st_loss:  65.6810 - ortho_loss :  5.3852 - sparse_loss :  112.9178\n",
      "Epoch 113/200\n",
      "3s - loss:  238.7988 - 2nd_loss:  55.4307 - 1st_loss:  65.4962 - ortho_loss :  5.3381 - sparse_loss :  112.4571\n",
      "Epoch 114/200\n",
      "3s - loss:  238.0732 - 2nd_loss:  55.4094 - 1st_loss:  65.2272 - ortho_loss :  5.3035 - sparse_loss :  112.0562\n",
      "Epoch 115/200\n",
      "3s - loss:  237.3237 - 2nd_loss:  55.3877 - 1st_loss:  65.0324 - ortho_loss :  5.2558 - sparse_loss :  111.5707\n",
      "Epoch 116/200\n",
      "3s - loss:  236.5655 - 2nd_loss:  55.3706 - 1st_loss:  64.7782 - ortho_loss :  5.2166 - sparse_loss :  111.1229\n",
      "Epoch 117/200\n",
      "3s - loss:  235.7464 - 2nd_loss:  55.3147 - 1st_loss:  64.5668 - ortho_loss :  5.1691 - sparse_loss :  110.6182\n",
      "Epoch 118/200\n",
      "3s - loss:  234.9277 - 2nd_loss:  55.2757 - 1st_loss:  64.3570 - ortho_loss :  5.1211 - sparse_loss :  110.0963\n",
      "Epoch 119/200\n",
      "3s - loss:  234.0907 - 2nd_loss:  55.2556 - 1st_loss:  64.1186 - ortho_loss :  5.0723 - sparse_loss :  109.5662\n",
      "Epoch 120/200\n",
      "3s - loss:  233.2325 - 2nd_loss:  55.2303 - 1st_loss:  63.9011 - ortho_loss :  5.0210 - sparse_loss :  109.0020\n",
      "Epoch 121/200\n",
      "3s - loss:  232.3499 - 2nd_loss:  55.2144 - 1st_loss:  63.6862 - ortho_loss :  4.9650 - sparse_loss :  108.4059\n",
      "Epoch 122/200\n",
      "3s - loss:  231.4286 - 2nd_loss:  55.1875 - 1st_loss:  63.4456 - ortho_loss :  4.9112 - sparse_loss :  107.8057\n",
      "Epoch 123/200\n",
      "3s - loss:  230.4454 - 2nd_loss:  55.1280 - 1st_loss:  63.2162 - ortho_loss :  4.8525 - sparse_loss :  107.1699\n",
      "Epoch 124/200\n",
      "3s - loss:  229.4068 - 2nd_loss:  55.0453 - 1st_loss:  62.9805 - ortho_loss :  4.7932 - sparse_loss :  106.5088\n",
      "Epoch 125/200\n",
      "3s - loss:  228.3756 - 2nd_loss:  55.0097 - 1st_loss:  62.7250 - ortho_loss :  4.7310 - sparse_loss :  105.8303\n",
      "Epoch 126/200\n",
      "3s - loss:  227.3265 - 2nd_loss:  54.9740 - 1st_loss:  62.4697 - ortho_loss :  4.6693 - sparse_loss :  105.1338\n",
      "Epoch 127/200\n",
      "3s - loss:  226.2519 - 2nd_loss:  54.9177 - 1st_loss:  62.1799 - ortho_loss :  4.6108 - sparse_loss :  104.4636\n",
      "Epoch 128/200\n",
      "3s - loss:  225.1660 - 2nd_loss:  54.8591 - 1st_loss:  61.8801 - ortho_loss :  4.5502 - sparse_loss :  103.7963\n",
      "Epoch 129/200\n",
      "3s - loss:  224.0409 - 2nd_loss:  54.7693 - 1st_loss:  61.5860 - ortho_loss :  4.4906 - sparse_loss :  103.1145\n",
      "Epoch 130/200\n",
      "3s - loss:  222.9778 - 2nd_loss:  54.7185 - 1st_loss:  61.2431 - ortho_loss :  4.4409 - sparse_loss :  102.4945\n",
      "Epoch 131/200\n",
      "3s - loss:  222.0513 - 2nd_loss:  54.6888 - 1st_loss:  60.9514 - ortho_loss :  4.3925 - sparse_loss :  101.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/200\n",
      "3s - loss:  221.2570 - 2nd_loss:  54.6756 - 1st_loss:  60.5790 - ortho_loss :  4.3643 - sparse_loss :  101.5567\n",
      "Epoch 133/200\n",
      "3s - loss:  220.4682 - 2nd_loss:  54.6477 - 1st_loss:  60.2894 - ortho_loss :  4.3271 - sparse_loss :  101.1224\n",
      "Epoch 134/200\n",
      "3s - loss:  219.6933 - 2nd_loss:  54.6283 - 1st_loss:  59.9521 - ortho_loss :  4.2970 - sparse_loss :  100.7340\n",
      "Epoch 135/200\n",
      "3s - loss:  218.8394 - 2nd_loss:  54.5253 - 1st_loss:  59.6608 - ortho_loss :  4.2626 - sparse_loss :  100.3085\n",
      "Epoch 136/200\n",
      "3s - loss:  218.0343 - 2nd_loss:  54.4654 - 1st_loss:  59.3824 - ortho_loss :  4.2282 - sparse_loss :  99.8758\n",
      "Epoch 137/200\n",
      "3s - loss:  217.2582 - 2nd_loss:  54.4352 - 1st_loss:  59.1046 - ortho_loss :  4.1939 - sparse_loss :  99.4418\n",
      "Epoch 138/200\n",
      "3s - loss:  216.4982 - 2nd_loss:  54.4117 - 1st_loss:  58.8374 - ortho_loss :  4.1597 - sparse_loss :  99.0063\n",
      "Epoch 139/200\n",
      "3s - loss:  215.7644 - 2nd_loss:  54.4012 - 1st_loss:  58.5600 - ortho_loss :  4.1274 - sparse_loss :  98.5924\n",
      "Epoch 140/200\n",
      "3s - loss:  215.0953 - 2nd_loss:  54.3969 - 1st_loss:  58.2926 - ortho_loss :  4.0982 - sparse_loss :  98.2241\n",
      "Epoch 141/200\n",
      "3s - loss:  214.5449 - 2nd_loss:  54.3933 - 1st_loss:  57.9963 - ortho_loss :  4.0797 - sparse_loss :  97.9918\n",
      "Epoch 142/200\n",
      "3s - loss:  214.0796 - 2nd_loss:  54.3916 - 1st_loss:  57.7160 - ortho_loss :  4.0644 - sparse_loss :  97.8235\n",
      "Epoch 143/200\n",
      "3s - loss:  213.5635 - 2nd_loss:  54.3477 - 1st_loss:  57.4322 - ortho_loss :  4.0495 - sparse_loss :  97.6498\n",
      "Epoch 144/200\n",
      "3s - loss:  213.0696 - 2nd_loss:  54.3347 - 1st_loss:  57.1905 - ortho_loss :  4.0292 - sparse_loss :  97.4306\n",
      "Epoch 145/200\n",
      "3s - loss:  212.5419 - 2nd_loss:  54.3175 - 1st_loss:  56.9184 - ortho_loss :  4.0105 - sparse_loss :  97.2107\n",
      "Epoch 146/200\n",
      "3s - loss:  212.0201 - 2nd_loss:  54.3075 - 1st_loss:  56.6907 - ortho_loss :  3.9872 - sparse_loss :  96.9496\n",
      "Epoch 147/200\n",
      "3s - loss:  211.4773 - 2nd_loss:  54.2931 - 1st_loss:  56.4274 - ortho_loss :  3.9675 - sparse_loss :  96.7040\n",
      "Epoch 148/200\n",
      "3s - loss:  210.8718 - 2nd_loss:  54.2441 - 1st_loss:  56.2231 - ortho_loss :  3.9374 - sparse_loss :  96.3815\n",
      "Epoch 149/200\n",
      "3s - loss:  210.2337 - 2nd_loss:  54.1773 - 1st_loss:  55.9480 - ortho_loss :  3.9149 - sparse_loss :  96.1076\n",
      "Epoch 150/200\n",
      "3s - loss:  209.6463 - 2nd_loss:  54.1506 - 1st_loss:  55.7279 - ortho_loss :  3.8876 - sparse_loss :  95.7940\n",
      "Epoch 151/200\n",
      "3s - loss:  208.9887 - 2nd_loss:  54.0604 - 1st_loss:  55.4410 - ortho_loss :  3.8668 - sparse_loss :  95.5341\n",
      "Epoch 152/200\n",
      "3s - loss:  208.3742 - 2nd_loss:  53.9915 - 1st_loss:  55.1707 - ortho_loss :  3.8457 - sparse_loss :  95.2796\n",
      "Epoch 153/200\n",
      "3s - loss:  207.8404 - 2nd_loss:  53.9649 - 1st_loss:  54.8650 - ortho_loss :  3.8318 - sparse_loss :  95.0917\n",
      "Epoch 154/200\n",
      "3s - loss:  207.2996 - 2nd_loss:  53.9024 - 1st_loss:  54.6211 - ortho_loss :  3.8127 - sparse_loss :  94.8761\n",
      "Epoch 155/200\n",
      "3s - loss:  206.7769 - 2nd_loss:  53.8269 - 1st_loss:  54.2912 - ortho_loss :  3.8062 - sparse_loss :  94.7651\n",
      "Epoch 156/200\n",
      "3s - loss:  206.3124 - 2nd_loss:  53.7762 - 1st_loss:  54.0999 - ortho_loss :  3.7861 - sparse_loss :  94.5624\n",
      "Epoch 157/200\n",
      "3s - loss:  205.7919 - 2nd_loss:  53.7194 - 1st_loss:  53.7657 - ortho_loss :  3.7781 - sparse_loss :  94.4407\n",
      "Epoch 158/200\n",
      "3s - loss:  205.3150 - 2nd_loss:  53.7000 - 1st_loss:  53.5861 - ortho_loss :  3.7546 - sparse_loss :  94.1860\n",
      "Epoch 159/200\n",
      "3s - loss:  204.8120 - 2nd_loss:  53.6879 - 1st_loss:  53.3047 - ortho_loss :  3.7394 - sparse_loss :  93.9915\n",
      "Epoch 160/200\n",
      "3s - loss:  204.3011 - 2nd_loss:  53.6804 - 1st_loss:  53.1312 - ortho_loss :  3.7124 - sparse_loss :  93.6882\n",
      "Epoch 161/200\n",
      "3s - loss:  203.7839 - 2nd_loss:  53.6758 - 1st_loss:  52.8745 - ortho_loss :  3.6942 - sparse_loss :  93.4503\n",
      "Epoch 162/200\n",
      "3s - loss:  203.2229 - 2nd_loss:  53.6620 - 1st_loss:  52.7306 - ortho_loss :  3.6609 - sparse_loss :  93.0800\n",
      "Epoch 163/200\n",
      "3s - loss:  202.6358 - 2nd_loss:  53.6509 - 1st_loss:  52.4463 - ortho_loss :  3.6403 - sparse_loss :  92.8086\n",
      "Epoch 164/200\n",
      "3s - loss:  202.0301 - 2nd_loss:  53.6302 - 1st_loss:  52.3035 - ortho_loss :  3.6048 - sparse_loss :  92.4018\n",
      "Epoch 165/200\n",
      "3s - loss:  201.3234 - 2nd_loss:  53.5502 - 1st_loss:  52.0343 - ortho_loss :  3.5790 - sparse_loss :  92.0696\n",
      "Epoch 166/200\n",
      "3s - loss:  200.5801 - 2nd_loss:  53.4474 - 1st_loss:  51.8756 - ortho_loss :  3.5410 - sparse_loss :  91.6255\n",
      "Epoch 167/200\n",
      "3s - loss:  199.8494 - 2nd_loss:  53.4024 - 1st_loss:  51.5974 - ortho_loss :  3.5114 - sparse_loss :  91.2473\n",
      "Epoch 168/200\n",
      "3s - loss:  199.1298 - 2nd_loss:  53.3892 - 1st_loss:  51.4239 - ortho_loss :  3.4698 - sparse_loss :  90.7557\n",
      "Epoch 169/200\n",
      "3s - loss:  198.2287 - 2nd_loss:  53.2302 - 1st_loss:  51.1422 - ortho_loss :  3.4369 - sparse_loss :  90.3278\n",
      "Epoch 170/200\n",
      "3s - loss:  197.3336 - 2nd_loss:  53.1016 - 1st_loss:  50.9704 - ortho_loss :  3.3909 - sparse_loss :  89.7787\n",
      "Epoch 171/200\n",
      "3s - loss:  196.4942 - 2nd_loss:  53.0757 - 1st_loss:  50.6724 - ortho_loss :  3.3542 - sparse_loss :  89.2996\n",
      "Epoch 172/200\n",
      "3s - loss:  195.7007 - 2nd_loss:  53.0592 - 1st_loss:  50.4703 - ortho_loss :  3.3115 - sparse_loss :  88.7669\n",
      "Epoch 173/200\n",
      "3s - loss:  194.9180 - 2nd_loss:  53.0291 - 1st_loss:  50.1546 - ortho_loss :  3.2830 - sparse_loss :  88.3583\n",
      "Epoch 174/200\n",
      "3s - loss:  194.0254 - 2nd_loss:  52.8521 - 1st_loss:  49.9123 - ortho_loss :  3.2508 - sparse_loss :  87.9168\n",
      "Epoch 175/200\n",
      "3s - loss:  193.2843 - 2nd_loss:  52.8341 - 1st_loss:  49.6170 - ortho_loss :  3.2239 - sparse_loss :  87.5155\n",
      "Epoch 176/200\n",
      "3s - loss:  192.5590 - 2nd_loss:  52.8308 - 1st_loss:  49.4150 - ortho_loss :  3.1887 - sparse_loss :  87.0304\n",
      "Epoch 177/200\n",
      "3s - loss:  191.8181 - 2nd_loss:  52.8246 - 1st_loss:  49.1579 - ortho_loss :  3.1586 - sparse_loss :  86.5825\n",
      "Epoch 178/200\n",
      "3s - loss:  191.0693 - 2nd_loss:  52.8216 - 1st_loss:  48.9941 - ortho_loss :  3.1186 - sparse_loss :  86.0403\n",
      "Epoch 179/200\n",
      "3s - loss:  190.2930 - 2nd_loss:  52.8185 - 1st_loss:  48.7205 - ortho_loss :  3.0877 - sparse_loss :  85.5713\n",
      "Epoch 180/200\n",
      "3s - loss:  189.5014 - 2nd_loss:  52.8091 - 1st_loss:  48.5509 - ortho_loss :  3.0462 - sparse_loss :  84.9998\n",
      "Epoch 181/200\n",
      "3s - loss:  188.6959 - 2nd_loss:  52.8059 - 1st_loss:  48.2940 - ortho_loss :  3.0129 - sparse_loss :  84.4874\n",
      "Epoch 182/200\n",
      "3s - loss:  187.8753 - 2nd_loss:  52.8025 - 1st_loss:  48.1135 - ortho_loss :  2.9702 - sparse_loss :  83.8931\n",
      "Epoch 183/200\n",
      "3s - loss:  187.0049 - 2nd_loss:  52.7969 - 1st_loss:  47.8319 - ortho_loss :  2.9340 - sparse_loss :  83.3457\n",
      "Epoch 184/200\n",
      "3s - loss:  186.0850 - 2nd_loss:  52.7550 - 1st_loss:  47.6122 - ortho_loss :  2.8913 - sparse_loss :  82.7299\n",
      "Epoch 185/200\n",
      "3s - loss:  185.1582 - 2nd_loss:  52.7216 - 1st_loss:  47.3635 - ortho_loss :  2.8514 - sparse_loss :  82.1249\n",
      "Epoch 186/200\n",
      "3s - loss:  184.2457 - 2nd_loss:  52.7113 - 1st_loss:  47.1152 - ortho_loss :  2.8104 - sparse_loss :  81.5115\n",
      "Epoch 187/200\n",
      "3s - loss:  183.2848 - 2nd_loss:  52.6862 - 1st_loss:  46.8675 - ortho_loss :  2.7669 - sparse_loss :  80.8667\n",
      "Epoch 188/200\n",
      "3s - loss:  182.2922 - 2nd_loss:  52.6705 - 1st_loss:  46.5414 - ortho_loss :  2.7266 - sparse_loss :  80.2560\n",
      "Epoch 189/200\n",
      "3s - loss:  181.3140 - 2nd_loss:  52.6363 - 1st_loss:  46.2794 - ortho_loss :  2.6832 - sparse_loss :  79.6170\n",
      "Epoch 190/200\n",
      "3s - loss:  180.3044 - 2nd_loss:  52.5750 - 1st_loss:  45.9489 - ortho_loss :  2.6459 - sparse_loss :  79.0362\n",
      "Epoch 191/200\n",
      "3s - loss:  179.3256 - 2nd_loss:  52.5180 - 1st_loss:  45.6571 - ortho_loss :  2.6059 - sparse_loss :  78.4458\n",
      "Epoch 192/200\n",
      "3s - loss:  178.3763 - 2nd_loss:  52.4801 - 1st_loss:  45.3578 - ortho_loss :  2.5673 - sparse_loss :  77.8721\n",
      "Epoch 193/200\n",
      "3s - loss:  177.5038 - 2nd_loss:  52.4546 - 1st_loss:  45.0190 - ortho_loss :  2.5340 - sparse_loss :  77.3968\n",
      "Epoch 194/200\n",
      "3s - loss:  176.5995 - 2nd_loss:  52.4194 - 1st_loss:  44.6474 - ortho_loss :  2.5021 - sparse_loss :  76.9308\n",
      "Epoch 195/200\n",
      "3s - loss:  175.6500 - 2nd_loss:  52.3587 - 1st_loss:  44.3357 - ortho_loss :  2.4642 - sparse_loss :  76.3914\n",
      "Epoch 196/200\n",
      "3s - loss:  174.6751 - 2nd_loss:  52.3361 - 1st_loss:  43.9748 - ortho_loss :  2.4270 - sparse_loss :  75.8369\n",
      "Epoch 197/200\n",
      "3s - loss:  173.6497 - 2nd_loss:  52.2996 - 1st_loss:  43.6513 - ortho_loss :  2.3844 - sparse_loss :  75.2137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 198/200\n",
      "3s - loss:  172.5539 - 2nd_loss:  52.2450 - 1st_loss:  43.2988 - ortho_loss :  2.3417 - sparse_loss :  74.5673\n",
      "Epoch 199/200\n",
      "3s - loss:  171.4759 - 2nd_loss:  52.1869 - 1st_loss:  42.9632 - ortho_loss :  2.2994 - sparse_loss :  73.9249\n",
      "Epoch 200/200\n",
      "3s - loss:  170.5186 - 2nd_loss:  52.1273 - 1st_loss:  42.5260 - ortho_loss :  2.2738 - sparse_loss :  73.4897\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohairshafi/miniforge3/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:1692: ConvergenceWarning: Maximum number of iterations 4000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n",
      "/Users/zohairshafi/Local Workspace/ExplainingNodeEmbeddings/scripts/utils.py:438: RuntimeWarning: overflow encountered in exp\n",
      "  explain_norm_softmax = np.array([np.exp(x) / sum(np.exp(x)) for x in explain_norm])\n",
      "/Users/zohairshafi/Local Workspace/ExplainingNodeEmbeddings/scripts/utils.py:438: RuntimeWarning: invalid value encountered in divide\n",
      "  explain_norm_softmax = np.array([np.exp(x) / sum(np.exp(x)) for x in explain_norm])\n",
      "/Users/zohairshafi/Local Workspace/ExplainingNodeEmbeddings/scripts/utils.py:438: RuntimeWarning: overflow encountered in exp\n",
      "  explain_norm_softmax = np.array([np.exp(x) / sum(np.exp(x)) for x in explain_norm])\n",
      "/Users/zohairshafi/Local Workspace/ExplainingNodeEmbeddings/scripts/utils.py:438: RuntimeWarning: invalid value encountered in divide\n",
      "  explain_norm_softmax = np.array([np.exp(x) / sum(np.exp(x)) for x in explain_norm])\n",
      "  0%|                                                     | 0/1 [32:20<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = './data/pubmed.pkl'\n",
    "run_count = 1\n",
    "hyp_key = 'hyp_pubmed'\n",
    "outfile = './pubmed_test.pkl'\n",
    "\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-g\", \"--graph_path\", required = True, help = 'Path to an nx.Graph object stored as a .pkl file')\n",
    "# ap.add_argument(\"-r\", \"--run_count\", required = True, help = \"Number of iterations for the experiment\", default = 1)\n",
    "# ap.add_argument(\"-k\", \"--hyp_key\", required = True, help = \"Key to index the hyperparameter json file\")\n",
    "# ap.add_argument(\"-o\", \"--outfile\", required = True, help = \"File name to save results into\")\n",
    "\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "# filename = args['graph_path']\n",
    "# run_count = args['run_count']\n",
    "# hyp_key = args['hyp_key']\n",
    "# outfile = args['outfile']\n",
    "\n",
    "#################################\n",
    "######### Read In Graph #########\n",
    "#################################\n",
    "with open(filename, 'rb') as file: \n",
    "    graph_dict = pkl.load(file)\n",
    "    \n",
    "try:\n",
    "    graph = nx.Graph(nx.to_numpy_array(graph_dict['graph']))    \n",
    "except:\n",
    "    graph = nx.Graph(nx.to_numpy_array(graph))\n",
    "\n",
    "\n",
    "#################################\n",
    "#### Generate Sense Features ####\n",
    "#################################\n",
    "sense_feat_dict, sense_features = get_sense_features(graph, ppr_flag = 'std')\n",
    "\n",
    "uncorrelated_feats = ['Degree',\n",
    "                    'Clustering Coefficient',\n",
    "                    'Personalized Page Rank - Standard Deviation',\n",
    "                    'Average Neighbor Degree',\n",
    "                    'Average Neighbor Clustering',\n",
    "                    'Eccentricity',\n",
    "                    'Katz Centrality']\n",
    "sense_features = sense_features[:, [list(sense_feat_dict).index(feat) for feat in uncorrelated_feats]]\n",
    "sense_feat_dict = {feat : idx for idx, feat in enumerate(uncorrelated_feats)}\n",
    "\n",
    "#################################\n",
    "######## Hyperparameters ########\n",
    "#################################\n",
    "\n",
    "# Define static ones to override or read in from a file\n",
    "\n",
    "if hyp_key == '':\n",
    "    hyp = {'sdne' : {'alpha' : 0.1, \n",
    "                     'beta' : 10, \n",
    "                     'gamma' : 0, \n",
    "                     'delta' : 0, \n",
    "                     'epochs' : 200, \n",
    "                     'batch_size' : 1024, \n",
    "                     'lr' : 1e-3}, \n",
    "\n",
    "          'sdne+xm' : {'alpha' : 1, \n",
    "                      'beta' : 1, \n",
    "                      'gamma' : 10, \n",
    "                      'delta' : 10, \n",
    "                      'epochs' : 400, \n",
    "                      'batch_size' : 1024, \n",
    "                      'lr' : 5e-4}}\n",
    "else: \n",
    "    with open('scripts/hyp.json', 'r') as file: \n",
    "        hyp_file = json.load(file)\n",
    "        hyp = hyp_file[hyp_key]\n",
    "\n",
    "\n",
    "#################################\n",
    "######## Run Experiment #########\n",
    "#################################\n",
    "\n",
    "dimensions = [16, 32, 64, 256, 512]\n",
    "dimensions = [64]\n",
    "\n",
    "results = {d : {} for d in dimensions}\n",
    "\n",
    "for run_idx in tqdm(range(run_count)):\n",
    "    \n",
    "    for d in dimensions: \n",
    "    \n",
    "        # Embed \n",
    "        \n",
    "        # Standard SDNE\n",
    "        sdne = SDNE_plus(graph, \n",
    "                          hidden_size = [32, d], \n",
    "                          lr = hyp['sdne']['lr'],\n",
    "                          sense_features = sense_features.astype(np.float32),\n",
    "                          alpha = hyp['sdne']['alpha'], \n",
    "                          beta = hyp['sdne']['beta'], \n",
    "                          gamma = hyp['sdne']['gamma'], \n",
    "                          delta = hyp['sdne']['delta'])\n",
    "        history = sdne.train(epochs = hyp['sdne']['epochs'], batch_size = hyp['sdne']['batch_size'])\n",
    "        e = sdne.get_embeddings()\n",
    "        embed_og = np.array([e[node_name] for node_name in graph.nodes()])\n",
    "        embed_og = (embed_og - np.min(embed_og)) / np.ptp(embed_og)\n",
    "\n",
    "        # SDNE+XM\n",
    "        sdne_plus = SDNE_plus(graph, \n",
    "                                  hidden_size = [32, d], \n",
    "                                  lr = hyp['sdne+xm']['lr'],\n",
    "                                  sense_features = sense_features.astype(np.float32),\n",
    "                                  alpha = hyp['sdne+xm']['alpha'], \n",
    "                                  beta = hyp['sdne+xm']['beta'], \n",
    "                                  gamma = hyp['sdne+xm']['gamma'], \n",
    "                                  delta = hyp['sdne+xm']['delta'])\n",
    "\n",
    "        sdne_plus.model.set_weights(sdne.model.get_weights())\n",
    "        history = sdne_plus.train(epochs = hyp['sdne+xm']['epochs'], batch_size = hyp['sdne+xm']['batch_size'])\n",
    "        e = sdne_plus.get_embeddings()\n",
    "        embed_plus = np.array([e[node_name] for node_name in graph.nodes()])\n",
    "        embed_plus = (embed_plus - np.min(embed_plus)) / np.ptp(embed_plus)\n",
    "        \n",
    "        # Generate Graph Explanations and Save\n",
    "        feature_dict_og = find_feature_membership(input_embed = embed_og,\n",
    "                                                    embed_name = 'SDNE',\n",
    "                                                    sense_features = sense_features,\n",
    "                                                    sense_feat_dict = sense_feat_dict,\n",
    "                                                    top_k = 8,\n",
    "                                                    solver = 'nmf')\n",
    "\n",
    "        explain_og = feature_dict_og['explain_norm']\n",
    "        explain_og = (explain_og - np.min(explain_og)) / np.ptp(explain_og)\n",
    "        explain_og_norm = np.linalg.norm(explain_og, ord = 'nuc')\n",
    "        \n",
    "        feature_dict_plus = find_feature_membership(input_embed = embed_plus,\n",
    "                                                            embed_name = 'SDNE+ Init',\n",
    "                                                            sense_features = sense_features,\n",
    "                                                            sense_feat_dict = sense_feat_dict,\n",
    "                                                            top_k = 8,\n",
    "                                                            solver = 'nmf')\n",
    "\n",
    "        explain_plus = feature_dict_plus['explain_norm']\n",
    "        explain_plus = (explain_plus - np.min(explain_plus)) / np.ptp(explain_plus)\n",
    "        explain_plus_norm = np.linalg.norm(explain_plus, ord = 'nuc')\n",
    "\n",
    "        # Generate Node Explanations\n",
    "        Y_og = embed_og\n",
    "        sense_mat = tf.einsum('ij, ik -> ijk', Y_og, sense_features)\n",
    "        Y_og_norm = tf.linalg.diag_part(tf.matmul(Y_og, Y_og, transpose_b = True), k = 0)\n",
    "        sense_norm = tf.linalg.diag_part(tf.matmul(sense_features, sense_features, transpose_b = True), k = 0)\n",
    "        norm = Y_og_norm * tf.cast(sense_norm, tf.float32)\n",
    "        D_og = tf.transpose(tf.transpose(sense_mat) / norm)\n",
    "\n",
    "\n",
    "        Y_plus = embed_plus\n",
    "        sense_mat = tf.einsum('ij, ik -> ijk', Y_plus, sense_features)\n",
    "        Y_plus_norm = tf.linalg.diag_part(tf.matmul(Y_plus, Y_plus, transpose_b = True), k = 0)\n",
    "        sense_norm = tf.linalg.diag_part(tf.matmul(sense_features, sense_features, transpose_b = True), k = 0)\n",
    "        norm = Y_plus_norm * tf.cast(sense_norm, tf.float32)\n",
    "        D_plus = tf.transpose(tf.transpose(sense_mat) / norm)\n",
    "\n",
    "        norm_og = [np.linalg.norm(D_og[node, :, :], ord = 'nuc') for node in range(len(graph))]\n",
    "        norm_plus = [np.linalg.norm(D_plus[node, :, :], ord = 'nuc') for node in range(len(graph))]\n",
    "        \n",
    "        try:\n",
    "            results[d]['norm_og'].append(norm_og)\n",
    "            results[d]['norm_plus'].append(norm_plus)\n",
    "            results[d]['explain_og_norm'].append(explain_og_norm)\n",
    "            results[d]['explain_plus_norm'].append(explain_plus_norm)\n",
    "            \n",
    "        except: \n",
    "            results[d]['norm_og'] = [norm_og]\n",
    "            results[d]['norm_plus'] = [norm_plus]\n",
    "            results[d]['explain_og_norm'] = [explain_og_norm]\n",
    "            results[d]['explain_plus_norm'] = [explain_plus_norm]\n",
    "            \n",
    "        results[d]['embed_og'] = embed_og\n",
    "        results[d]['embed_plus'] = embed_plus\n",
    "    \n",
    "    with open(outfile, 'wb') as file: \n",
    "        pkl.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af0218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "565ae61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Personalized Page Rank...                     \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "986it [00:22, 44.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Node Betweenness...                           \r",
      "Calculating Number Of Edges In Ego Nets...                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohairshafi/miniforge3/lib/python3.10/site-packages/networkx/algorithms/centrality/katz.py:325: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(G, nodelist=nodelist, weight=weight).todense().T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Structural Hole Constraint Scores...         \r",
      "Calculating Degree Centrality...                         \r",
      "Calculating Eigen Centrality...                          \r",
      "Calculating Katz Centrality...                           \r",
      "Normalizing Features Between 0 And 1...                   \r",
      "Done                                                      \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2be0ca950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2be0ca950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2be0ca710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2be0ca710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2be0ca4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2be0ca4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:05:35.975029: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 3s 22ms/step - loss: 0.0686 - ortho_2_loss: 0.0686 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 2/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0670 - ortho_2_loss: 0.0670 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 3/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0654 - ortho_2_loss: 0.0654 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 4/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0642 - ortho_2_loss: 0.0642 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 5/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0627 - ortho_2_loss: 0.0627 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 6/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0615 - ortho_2_loss: 0.0615 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 7/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0607 - ortho_2_loss: 0.0607 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 8/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0593 - ortho_2_loss: 0.0593 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 9/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0583 - ortho_2_loss: 0.0583 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 10/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0578 - ortho_2_loss: 0.0578 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 11/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0565 - ortho_2_loss: 0.0565 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 12/15\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 0.0557 - ortho_2_loss: 0.0557 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 13/15\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 0.0555 - ortho_2_loss: 0.0555 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 14/15\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 0.0543 - ortho_2_loss: 0.0543 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 15/15\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 0.0537 - ortho_2_loss: 0.0537 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2bd55e440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2bd55e440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2bd55dc60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2bd55dc60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2bd55d990> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2bd55d990> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:06:00.095603: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 3s 20ms/step - loss: 780.2347 - ortho_2_loss: 69.3413 - tf.math.reduce_sum_11_loss: 141.9788 - tf.math.multiply_23_loss: 568.9145\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 379.4205 - ortho_2_loss: 69.3726 - tf.math.reduce_sum_11_loss: 4.3295 - tf.math.multiply_23_loss: 305.7186\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 288.6990 - ortho_2_loss: 69.4214 - tf.math.reduce_sum_11_loss: 2.2049 - tf.math.multiply_23_loss: 217.0727\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 237.8753 - ortho_2_loss: 69.4875 - tf.math.reduce_sum_11_loss: 1.4923 - tf.math.multiply_23_loss: 166.8955\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 204.0805 - ortho_2_loss: 69.5763 - tf.math.reduce_sum_11_loss: 0.8962 - tf.math.multiply_23_loss: 133.6080\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 183.3327 - ortho_2_loss: 69.6694 - tf.math.reduce_sum_11_loss: 0.7633 - tf.math.multiply_23_loss: 112.9001\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 166.2986 - ortho_2_loss: 69.7859 - tf.math.reduce_sum_11_loss: 0.5118 - tf.math.multiply_23_loss: 96.0010\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 154.6747 - ortho_2_loss: 69.9091 - tf.math.reduce_sum_11_loss: 0.4106 - tf.math.multiply_23_loss: 84.3550\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 144.7557 - ortho_2_loss: 70.0492 - tf.math.reduce_sum_11_loss: 0.3320 - tf.math.multiply_23_loss: 74.3745\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 137.8974 - ortho_2_loss: 70.1825 - tf.math.reduce_sum_11_loss: 0.3128 - tf.math.multiply_23_loss: 67.4023\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 131.4819 - ortho_2_loss: 70.3301 - tf.math.reduce_sum_11_loss: 0.2669 - tf.math.multiply_23_loss: 60.8848\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 126.7352 - ortho_2_loss: 70.4663 - tf.math.reduce_sum_11_loss: 0.2427 - tf.math.multiply_23_loss: 56.0262\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 122.6697 - ortho_2_loss: 70.6194 - tf.math.reduce_sum_11_loss: 0.2379 - tf.math.multiply_23_loss: 51.8124\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 119.0892 - ortho_2_loss: 70.7391 - tf.math.reduce_sum_11_loss: 0.2373 - tf.math.multiply_23_loss: 48.1128\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 116.1673 - ortho_2_loss: 70.8623 - tf.math.reduce_sum_11_loss: 0.2362 - tf.math.multiply_23_loss: 45.0688\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 113.6046 - ortho_2_loss: 70.9982 - tf.math.reduce_sum_11_loss: 0.2526 - tf.math.multiply_23_loss: 42.3538\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 111.3640 - ortho_2_loss: 71.0534 - tf.math.reduce_sum_11_loss: 0.2754 - tf.math.multiply_23_loss: 40.0352\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 109.3411 - ortho_2_loss: 71.1188 - tf.math.reduce_sum_11_loss: 0.3035 - tf.math.multiply_23_loss: 37.9188\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 107.5168 - ortho_2_loss: 71.2037 - tf.math.reduce_sum_11_loss: 0.3398 - tf.math.multiply_23_loss: 35.9734\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 105.9335 - ortho_2_loss: 71.1553 - tf.math.reduce_sum_11_loss: 0.3918 - tf.math.multiply_23_loss: 34.3864\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 104.5056 - ortho_2_loss: 71.1352 - tf.math.reduce_sum_11_loss: 0.4468 - tf.math.multiply_23_loss: 32.9236\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 103.2812 - ortho_2_loss: 71.1588 - tf.math.reduce_sum_11_loss: 0.5067 - tf.math.multiply_23_loss: 31.6157\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 101.9042 - ortho_2_loss: 70.9823 - tf.math.reduce_sum_11_loss: 0.5911 - tf.math.multiply_23_loss: 30.3308\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 100.7171 - ortho_2_loss: 70.8551 - tf.math.reduce_sum_11_loss: 0.6749 - tf.math.multiply_23_loss: 29.1870\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 99.7537 - ortho_2_loss: 70.8222 - tf.math.reduce_sum_11_loss: 0.7626 - tf.math.multiply_23_loss: 28.1689\n",
      "Epoch 26/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 98.5185 - ortho_2_loss: 70.4958 - tf.math.reduce_sum_11_loss: 0.8629 - tf.math.multiply_23_loss: 27.1598\n",
      "Epoch 27/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 97.5353 - ortho_2_loss: 70.3484 - tf.math.reduce_sum_11_loss: 0.9663 - tf.math.multiply_23_loss: 26.2206\n",
      "Epoch 28/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 96.6270 - ortho_2_loss: 70.2330 - tf.math.reduce_sum_11_loss: 1.0781 - tf.math.multiply_23_loss: 25.3159\n",
      "Epoch 29/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 95.5708 - ortho_2_loss: 69.8442 - tf.math.reduce_sum_11_loss: 1.1809 - tf.math.multiply_23_loss: 24.5457\n",
      "Epoch 30/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 94.6749 - ortho_2_loss: 69.5800 - tf.math.reduce_sum_11_loss: 1.2892 - tf.math.multiply_23_loss: 23.8057\n",
      "Epoch 31/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 93.9856 - ortho_2_loss: 69.5182 - tf.math.reduce_sum_11_loss: 1.3971 - tf.math.multiply_23_loss: 23.0704\n",
      "Epoch 32/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 92.8414 - ortho_2_loss: 69.0165 - tf.math.reduce_sum_11_loss: 1.5066 - tf.math.multiply_23_loss: 22.3183\n",
      "Epoch 33/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 92.1299 - ortho_2_loss: 68.7617 - tf.math.reduce_sum_11_loss: 1.5945 - tf.math.multiply_23_loss: 21.7737\n",
      "Epoch 34/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 91.4978 - ortho_2_loss: 68.7216 - tf.math.reduce_sum_11_loss: 1.6946 - tf.math.multiply_23_loss: 21.0816\n",
      "Epoch 35/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 90.5595 - ortho_2_loss: 68.1931 - tf.math.reduce_sum_11_loss: 1.7871 - tf.math.multiply_23_loss: 20.5793\n",
      "Epoch 36/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 89.7815 - ortho_2_loss: 67.9065 - tf.math.reduce_sum_11_loss: 1.8643 - tf.math.multiply_23_loss: 20.0106\n",
      "Epoch 37/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 89.3000 - ortho_2_loss: 67.8870 - tf.math.reduce_sum_11_loss: 1.9592 - tf.math.multiply_23_loss: 19.4538\n",
      "Epoch 38/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 88.2864 - ortho_2_loss: 67.3075 - tf.math.reduce_sum_11_loss: 2.0412 - tf.math.multiply_23_loss: 18.9377\n",
      "Epoch 39/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 87.7300 - ortho_2_loss: 67.0506 - tf.math.reduce_sum_11_loss: 2.1061 - tf.math.multiply_23_loss: 18.5733\n",
      "Epoch 40/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 87.2720 - ortho_2_loss: 67.1120 - tf.math.reduce_sum_11_loss: 2.1647 - tf.math.multiply_23_loss: 17.9953\n",
      "Epoch 41/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 86.4004 - ortho_2_loss: 66.4893 - tf.math.reduce_sum_11_loss: 2.2240 - tf.math.multiply_23_loss: 17.6872\n",
      "Epoch 42/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 85.8835 - ortho_2_loss: 66.2918 - tf.math.reduce_sum_11_loss: 2.2719 - tf.math.multiply_23_loss: 17.3198\n",
      "Epoch 43/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 85.6873 - ortho_2_loss: 66.4193 - tf.math.reduce_sum_11_loss: 2.3105 - tf.math.multiply_23_loss: 16.9575\n",
      "Epoch 44/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 84.8246 - ortho_2_loss: 65.8042 - tf.math.reduce_sum_11_loss: 2.3658 - tf.math.multiply_23_loss: 16.6546\n",
      "Epoch 45/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 84.2936 - ortho_2_loss: 65.5671 - tf.math.reduce_sum_11_loss: 2.3915 - tf.math.multiply_23_loss: 16.3350\n",
      "Epoch 46/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 84.2397 - ortho_2_loss: 65.7772 - tf.math.reduce_sum_11_loss: 2.4270 - tf.math.multiply_23_loss: 16.0354\n",
      "Epoch 47/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 83.3559 - ortho_2_loss: 65.1326 - tf.math.reduce_sum_11_loss: 2.4605 - tf.math.multiply_23_loss: 15.7628\n",
      "Epoch 48/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 82.8866 - ortho_2_loss: 64.8934 - tf.math.reduce_sum_11_loss: 2.4877 - tf.math.multiply_23_loss: 15.5055\n",
      "Epoch 49/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 82.9342 - ortho_2_loss: 65.1700 - tf.math.reduce_sum_11_loss: 2.5117 - tf.math.multiply_23_loss: 15.2524\n",
      "Epoch 50/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 82.0378 - ortho_2_loss: 64.4720 - tf.math.reduce_sum_11_loss: 2.5352 - tf.math.multiply_23_loss: 15.0306\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2bdb2b2e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2bdb2b2e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2bdb28ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2bdb28ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2bdb2a3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2bdb2a3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:07:46.045346: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 3s 24ms/step - loss: 0.0686 - ortho_2_loss: 0.0686 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 2/15\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.0671 - ortho_2_loss: 0.0671 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 3/15\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 0.0655 - ortho_2_loss: 0.0655 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 4/15\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.0643 - ortho_2_loss: 0.0643 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 5/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0629 - ortho_2_loss: 0.0629 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 6/15\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 0.0616 - ortho_2_loss: 0.0616 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 7/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0608 - ortho_2_loss: 0.0608 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 8/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0594 - ortho_2_loss: 0.0594 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 9/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0584 - ortho_2_loss: 0.0584 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 10/15\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.0580 - ortho_2_loss: 0.0580 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 11/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0567 - ortho_2_loss: 0.0567 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 12/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0559 - ortho_2_loss: 0.0559 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 13/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0557 - ortho_2_loss: 0.0557 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 14/15\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.0545 - ortho_2_loss: 0.0545 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 15/15\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.0538 - ortho_2_loss: 0.0538 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2bd55e320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2bd55e320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2bd55dbd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2bd55dbd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2bd55d510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2bd55d510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:08:11.637698: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 3s 24ms/step - loss: 675.3688 - ortho_2_loss: 69.3348 - tf.math.reduce_sum_13_loss: 59.3795 - tf.math.multiply_27_loss: 546.6546\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 367.4493 - ortho_2_loss: 69.3722 - tf.math.reduce_sum_13_loss: 2.1345 - tf.math.multiply_27_loss: 295.9426\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 279.4481 - ortho_2_loss: 69.4227 - tf.math.reduce_sum_13_loss: 1.3615 - tf.math.multiply_27_loss: 208.6639\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 234.2339 - ortho_2_loss: 69.4880 - tf.math.reduce_sum_13_loss: 0.9626 - tf.math.multiply_27_loss: 163.7832\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 203.8941 - ortho_2_loss: 69.5668 - tf.math.reduce_sum_13_loss: 0.6932 - tf.math.multiply_27_loss: 133.6341\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 182.5330 - ortho_2_loss: 69.6610 - tf.math.reduce_sum_13_loss: 0.4728 - tf.math.multiply_27_loss: 112.3992\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 166.6379 - ortho_2_loss: 69.7739 - tf.math.reduce_sum_13_loss: 0.3478 - tf.math.multiply_27_loss: 96.5163\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 154.1031 - ortho_2_loss: 69.8984 - tf.math.reduce_sum_13_loss: 0.2695 - tf.math.multiply_27_loss: 83.9353\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 145.5388 - ortho_2_loss: 70.0253 - tf.math.reduce_sum_13_loss: 0.2462 - tf.math.multiply_27_loss: 75.2674\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 137.9593 - ortho_2_loss: 70.1693 - tf.math.reduce_sum_13_loss: 0.2039 - tf.math.multiply_27_loss: 67.5861\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 131.8694 - ortho_2_loss: 70.3027 - tf.math.reduce_sum_13_loss: 0.1866 - tf.math.multiply_27_loss: 61.3802\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 127.1360 - ortho_2_loss: 70.4424 - tf.math.reduce_sum_13_loss: 0.1785 - tf.math.multiply_27_loss: 56.5152\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 122.9268 - ortho_2_loss: 70.5870 - tf.math.reduce_sum_13_loss: 0.1824 - tf.math.multiply_27_loss: 52.1574\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 119.4902 - ortho_2_loss: 70.7028 - tf.math.reduce_sum_13_loss: 0.1868 - tf.math.multiply_27_loss: 48.6006\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 116.5415 - ortho_2_loss: 70.8029 - tf.math.reduce_sum_13_loss: 0.2061 - tf.math.multiply_27_loss: 45.5324\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 113.8320 - ortho_2_loss: 70.9409 - tf.math.reduce_sum_13_loss: 0.2236 - tf.math.multiply_27_loss: 42.6674\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 111.5619 - ortho_2_loss: 71.0012 - tf.math.reduce_sum_13_loss: 0.2516 - tf.math.multiply_27_loss: 40.3091\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 109.5187 - ortho_2_loss: 71.0605 - tf.math.reduce_sum_13_loss: 0.2852 - tf.math.multiply_27_loss: 38.1730\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 107.6207 - ortho_2_loss: 71.1511 - tf.math.reduce_sum_13_loss: 0.3282 - tf.math.multiply_27_loss: 36.1414\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 106.1419 - ortho_2_loss: 71.1222 - tf.math.reduce_sum_13_loss: 0.3747 - tf.math.multiply_27_loss: 34.6450\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 104.5504 - ortho_2_loss: 71.1173 - tf.math.reduce_sum_13_loss: 0.4281 - tf.math.multiply_27_loss: 33.0050\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 103.2720 - ortho_2_loss: 71.1392 - tf.math.reduce_sum_13_loss: 0.4956 - tf.math.multiply_27_loss: 31.6373\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 102.0771 - ortho_2_loss: 71.0138 - tf.math.reduce_sum_13_loss: 0.5627 - tf.math.multiply_27_loss: 30.5006\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 100.8245 - ortho_2_loss: 70.9093 - tf.math.reduce_sum_13_loss: 0.6400 - tf.math.multiply_27_loss: 29.2752\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 99.8300 - ortho_2_loss: 70.8957 - tf.math.reduce_sum_13_loss: 0.7251 - tf.math.multiply_27_loss: 28.2092\n",
      "Epoch 26/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 98.6542 - ortho_2_loss: 70.6011 - tf.math.reduce_sum_13_loss: 0.8166 - tf.math.multiply_27_loss: 27.2365\n",
      "Epoch 27/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 97.7070 - ortho_2_loss: 70.4775 - tf.math.reduce_sum_13_loss: 0.9129 - tf.math.multiply_27_loss: 26.3166\n",
      "Epoch 28/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 96.8818 - ortho_2_loss: 70.3965 - tf.math.reduce_sum_13_loss: 1.0132 - tf.math.multiply_27_loss: 25.4721\n",
      "Epoch 29/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 95.8739 - ortho_2_loss: 70.0344 - tf.math.reduce_sum_13_loss: 1.1118 - tf.math.multiply_27_loss: 24.7277\n",
      "Epoch 30/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 94.9736 - ortho_2_loss: 69.8064 - tf.math.reduce_sum_13_loss: 1.2070 - tf.math.multiply_27_loss: 23.9602\n",
      "Epoch 31/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 94.4088 - ortho_2_loss: 69.7845 - tf.math.reduce_sum_13_loss: 1.3022 - tf.math.multiply_27_loss: 23.3220\n",
      "Epoch 32/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 93.4843 - ortho_2_loss: 69.3567 - tf.math.reduce_sum_13_loss: 1.3938 - tf.math.multiply_27_loss: 22.7339\n",
      "Epoch 33/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 92.7443 - ortho_2_loss: 69.1303 - tf.math.reduce_sum_13_loss: 1.4792 - tf.math.multiply_27_loss: 22.1349\n",
      "Epoch 34/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 92.3247 - ortho_2_loss: 69.1465 - tf.math.reduce_sum_13_loss: 1.5560 - tf.math.multiply_27_loss: 21.6223\n",
      "Epoch 35/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 91.4030 - ortho_2_loss: 68.6775 - tf.math.reduce_sum_13_loss: 1.6426 - tf.math.multiply_27_loss: 21.0829\n",
      "Epoch 36/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 90.7776 - ortho_2_loss: 68.4275 - tf.math.reduce_sum_13_loss: 1.7230 - tf.math.multiply_27_loss: 20.6271\n",
      "Epoch 37/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 90.4719 - ortho_2_loss: 68.5191 - tf.math.reduce_sum_13_loss: 1.7812 - tf.math.multiply_27_loss: 20.1716\n",
      "Epoch 38/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 89.5912 - ortho_2_loss: 67.9999 - tf.math.reduce_sum_13_loss: 1.8571 - tf.math.multiply_27_loss: 19.7342\n",
      "Epoch 39/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 89.0089 - ortho_2_loss: 67.7869 - tf.math.reduce_sum_13_loss: 1.9163 - tf.math.multiply_27_loss: 19.3057\n",
      "Epoch 40/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 88.7344 - ortho_2_loss: 67.8781 - tf.math.reduce_sum_13_loss: 1.9718 - tf.math.multiply_27_loss: 18.8846\n",
      "Epoch 41/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 87.9668 - ortho_2_loss: 67.3652 - tf.math.reduce_sum_13_loss: 2.0325 - tf.math.multiply_27_loss: 18.5691\n",
      "Epoch 42/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 87.3427 - ortho_2_loss: 67.1521 - tf.math.reduce_sum_13_loss: 2.0798 - tf.math.multiply_27_loss: 18.1108\n",
      "Epoch 43/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 87.3011 - ortho_2_loss: 67.3146 - tf.math.reduce_sum_13_loss: 2.1259 - tf.math.multiply_27_loss: 17.8606\n",
      "Epoch 44/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 86.3510 - ortho_2_loss: 66.7324 - tf.math.reduce_sum_13_loss: 2.1722 - tf.math.multiply_27_loss: 17.4464\n",
      "Epoch 45/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 85.9740 - ortho_2_loss: 66.5758 - tf.math.reduce_sum_13_loss: 2.2085 - tf.math.multiply_27_loss: 17.1897\n",
      "Epoch 46/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 85.8619 - ortho_2_loss: 66.7775 - tf.math.reduce_sum_13_loss: 2.2368 - tf.math.multiply_27_loss: 16.8477\n",
      "Epoch 47/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 85.0585 - ortho_2_loss: 66.2185 - tf.math.reduce_sum_13_loss: 2.2709 - tf.math.multiply_27_loss: 16.5691\n",
      "Epoch 48/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 84.6498 - ortho_2_loss: 66.0396 - tf.math.reduce_sum_13_loss: 2.3025 - tf.math.multiply_27_loss: 16.3077\n",
      "Epoch 49/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 84.6285 - ortho_2_loss: 66.2949 - tf.math.reduce_sum_13_loss: 2.3255 - tf.math.multiply_27_loss: 16.0081\n",
      "Epoch 50/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 83.8235 - ortho_2_loss: 65.6970 - tf.math.reduce_sum_13_loss: 2.3486 - tf.math.multiply_27_loss: 15.7779\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2ccf305e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2ccf305e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2ccf30670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2ccf30670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2ccf30700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2ccf30700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:10:08.664012: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 4s 32ms/step - loss: 0.0687 - ortho_2_loss: 0.0687 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 2/15\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 0.0672 - ortho_2_loss: 0.0672 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 3/15\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 0.0658 - ortho_2_loss: 0.0658 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 4/15\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 0.0646 - ortho_2_loss: 0.0646 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 5/15\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 0.0632 - ortho_2_loss: 0.0632 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 6/15\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 0.0620 - ortho_2_loss: 0.0620 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 7/15\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 0.0612 - ortho_2_loss: 0.0612 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 8/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0598 - ortho_2_loss: 0.0598 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 9/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0588 - ortho_2_loss: 0.0588 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 10/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0584 - ortho_2_loss: 0.0584 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 11/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0571 - ortho_2_loss: 0.0571 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 12/15\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 0.0563 - ortho_2_loss: 0.0563 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 13/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0561 - ortho_2_loss: 0.0561 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 14/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0549 - ortho_2_loss: 0.0549 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 15/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0542 - ortho_2_loss: 0.0542 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2ccf32a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2ccf32a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2ccf32b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2ccf32b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2ccf32b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2ccf32b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:10:44.763946: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 4s 31ms/step - loss: 617.1133 - ortho_2_loss: 69.3360 - tf.math.reduce_sum_15_loss: 14.7288 - tf.math.multiply_31_loss: 533.0487\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 3s 28ms/step - loss: 367.5789 - ortho_2_loss: 69.3723 - tf.math.reduce_sum_15_loss: 1.5063 - tf.math.multiply_31_loss: 296.7002\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 3s 26ms/step - loss: 282.9397 - ortho_2_loss: 69.4234 - tf.math.reduce_sum_15_loss: 1.1289 - tf.math.multiply_31_loss: 212.3874\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 3s 26ms/step - loss: 238.3148 - ortho_2_loss: 69.4834 - tf.math.reduce_sum_15_loss: 0.6730 - tf.math.multiply_31_loss: 168.1585\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 209.0697 - ortho_2_loss: 69.5568 - tf.math.reduce_sum_15_loss: 0.5233 - tf.math.multiply_31_loss: 138.9895\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 186.1237 - ortho_2_loss: 69.6518 - tf.math.reduce_sum_15_loss: 0.2638 - tf.math.multiply_31_loss: 116.2081\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 169.8141 - ortho_2_loss: 69.7595 - tf.math.reduce_sum_15_loss: 0.1942 - tf.math.multiply_31_loss: 99.8604\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 156.9545 - ortho_2_loss: 69.8832 - tf.math.reduce_sum_15_loss: 0.1383 - tf.math.multiply_31_loss: 86.9329\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 147.3440 - ortho_2_loss: 70.0111 - tf.math.reduce_sum_15_loss: 0.1273 - tf.math.multiply_31_loss: 77.2056\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 139.4531 - ortho_2_loss: 70.1517 - tf.math.reduce_sum_15_loss: 0.1131 - tf.math.multiply_31_loss: 69.1882\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 133.4199 - ortho_2_loss: 70.2861 - tf.math.reduce_sum_15_loss: 0.1093 - tf.math.multiply_31_loss: 63.0245\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 128.3271 - ortho_2_loss: 70.4240 - tf.math.reduce_sum_15_loss: 0.1170 - tf.math.multiply_31_loss: 57.7860\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 124.0105 - ortho_2_loss: 70.5689 - tf.math.reduce_sum_15_loss: 0.1265 - tf.math.multiply_31_loss: 53.3151\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 120.2213 - ortho_2_loss: 70.6845 - tf.math.reduce_sum_15_loss: 0.1452 - tf.math.multiply_31_loss: 49.3916\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 117.1984 - ortho_2_loss: 70.7895 - tf.math.reduce_sum_15_loss: 0.1715 - tf.math.multiply_31_loss: 46.2374\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 114.4819 - ortho_2_loss: 70.9124 - tf.math.reduce_sum_15_loss: 0.2058 - tf.math.multiply_31_loss: 43.3637\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 112.0845 - ortho_2_loss: 70.9478 - tf.math.reduce_sum_15_loss: 0.2492 - tf.math.multiply_31_loss: 40.8874\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 110.0501 - ortho_2_loss: 70.9930 - tf.math.reduce_sum_15_loss: 0.2969 - tf.math.multiply_31_loss: 38.7602\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 108.1294 - ortho_2_loss: 71.0645 - tf.math.reduce_sum_15_loss: 0.3519 - tf.math.multiply_31_loss: 36.7130\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 106.3885 - ortho_2_loss: 71.0247 - tf.math.reduce_sum_15_loss: 0.4121 - tf.math.multiply_31_loss: 34.9518\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 104.9207 - ortho_2_loss: 70.9884 - tf.math.reduce_sum_15_loss: 0.4793 - tf.math.multiply_31_loss: 33.4530\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 103.5329 - ortho_2_loss: 71.0294 - tf.math.reduce_sum_15_loss: 0.5471 - tf.math.multiply_31_loss: 31.9564\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 102.2833 - ortho_2_loss: 70.8884 - tf.math.reduce_sum_15_loss: 0.6211 - tf.math.multiply_31_loss: 30.7739\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 101.1417 - ortho_2_loss: 70.8033 - tf.math.reduce_sum_15_loss: 0.6885 - tf.math.multiply_31_loss: 29.6499\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 100.2469 - ortho_2_loss: 70.8267 - tf.math.reduce_sum_15_loss: 0.7565 - tf.math.multiply_31_loss: 28.6637\n",
      "Epoch 26/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 99.1958 - ortho_2_loss: 70.5863 - tf.math.reduce_sum_15_loss: 0.8269 - tf.math.multiply_31_loss: 27.7826\n",
      "Epoch 27/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 98.3838 - ortho_2_loss: 70.5264 - tf.math.reduce_sum_15_loss: 0.8963 - tf.math.multiply_31_loss: 26.9612\n",
      "Epoch 28/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 97.7508 - ortho_2_loss: 70.5136 - tf.math.reduce_sum_15_loss: 0.9649 - tf.math.multiply_31_loss: 26.2722\n",
      "Epoch 29/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 96.8226 - ortho_2_loss: 70.2291 - tf.math.reduce_sum_15_loss: 1.0380 - tf.math.multiply_31_loss: 25.5555\n",
      "Epoch 30/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 96.1622 - ortho_2_loss: 70.0917 - tf.math.reduce_sum_15_loss: 1.1006 - tf.math.multiply_31_loss: 24.9700\n",
      "Epoch 31/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 95.6969 - ortho_2_loss: 70.1197 - tf.math.reduce_sum_15_loss: 1.1700 - tf.math.multiply_31_loss: 24.4072\n",
      "Epoch 32/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 94.8619 - ortho_2_loss: 69.7803 - tf.math.reduce_sum_15_loss: 1.2397 - tf.math.multiply_31_loss: 23.8419\n",
      "Epoch 33/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 94.2124 - ortho_2_loss: 69.6117 - tf.math.reduce_sum_15_loss: 1.3099 - tf.math.multiply_31_loss: 23.2908\n",
      "Epoch 34/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 93.8894 - ortho_2_loss: 69.6439 - tf.math.reduce_sum_15_loss: 1.3734 - tf.math.multiply_31_loss: 22.8721\n",
      "Epoch 35/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 93.0542 - ortho_2_loss: 69.2745 - tf.math.reduce_sum_15_loss: 1.4376 - tf.math.multiply_31_loss: 22.3420\n",
      "Epoch 36/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 92.5247 - ortho_2_loss: 69.0837 - tf.math.reduce_sum_15_loss: 1.5057 - tf.math.multiply_31_loss: 21.9352\n",
      "Epoch 37/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 92.1700 - ortho_2_loss: 69.1291 - tf.math.reduce_sum_15_loss: 1.5740 - tf.math.multiply_31_loss: 21.4669\n",
      "Epoch 38/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 91.4390 - ortho_2_loss: 68.7212 - tf.math.reduce_sum_15_loss: 1.6340 - tf.math.multiply_31_loss: 21.0838\n",
      "Epoch 39/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 90.9212 - ortho_2_loss: 68.5160 - tf.math.reduce_sum_15_loss: 1.6961 - tf.math.multiply_31_loss: 20.7091\n",
      "Epoch 40/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 90.5932 - ortho_2_loss: 68.5888 - tf.math.reduce_sum_15_loss: 1.7535 - tf.math.multiply_31_loss: 20.2509\n",
      "Epoch 41/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 89.8143 - ortho_2_loss: 68.1172 - tf.math.reduce_sum_15_loss: 1.8147 - tf.math.multiply_31_loss: 19.8824\n",
      "Epoch 42/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 89.3889 - ortho_2_loss: 67.9404 - tf.math.reduce_sum_15_loss: 1.8674 - tf.math.multiply_31_loss: 19.5812\n",
      "Epoch 43/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 89.1551 - ortho_2_loss: 68.0503 - tf.math.reduce_sum_15_loss: 1.9217 - tf.math.multiply_31_loss: 19.1831\n",
      "Epoch 44/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 88.3316 - ortho_2_loss: 67.5339 - tf.math.reduce_sum_15_loss: 1.9761 - tf.math.multiply_31_loss: 18.8216\n",
      "Epoch 45/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 87.9943 - ortho_2_loss: 67.3798 - tf.math.reduce_sum_15_loss: 2.0122 - tf.math.multiply_31_loss: 18.6024\n",
      "Epoch 46/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 87.7544 - ortho_2_loss: 67.4823 - tf.math.reduce_sum_15_loss: 2.0692 - tf.math.multiply_31_loss: 18.2029\n",
      "Epoch 47/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 86.9603 - ortho_2_loss: 66.9823 - tf.math.reduce_sum_15_loss: 2.1102 - tf.math.multiply_31_loss: 17.8678\n",
      "Epoch 48/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 86.5204 - ortho_2_loss: 66.7582 - tf.math.reduce_sum_15_loss: 2.1531 - tf.math.multiply_31_loss: 17.6092\n",
      "Epoch 49/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 86.4774 - ortho_2_loss: 66.9895 - tf.math.reduce_sum_15_loss: 2.1888 - tf.math.multiply_31_loss: 17.2991\n",
      "Epoch 50/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 85.6261 - ortho_2_loss: 66.3986 - tf.math.reduce_sum_15_loss: 2.2272 - tf.math.multiply_31_loss: 17.0003\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x5c55b4f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x5c55b4f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x5c55b5000> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x5c55b5000> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x5c55b5090> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x5c55b5090> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:14:01.573158: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 14s 135ms/step - loss: 0.0689 - ortho_2_loss: 0.0689 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 2/15\n",
      "98/98 [==============================] - 12s 127ms/step - loss: 0.0678 - ortho_2_loss: 0.0678 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 3/15\n",
      "98/98 [==============================] - 12s 125ms/step - loss: 0.0666 - ortho_2_loss: 0.0666 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 4/15\n",
      "98/98 [==============================] - 12s 125ms/step - loss: 0.0656 - ortho_2_loss: 0.0656 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 5/15\n",
      "98/98 [==============================] - 12s 123ms/step - loss: 0.0644 - ortho_2_loss: 0.0644 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 6/15\n",
      "98/98 [==============================] - 12s 122ms/step - loss: 0.0633 - ortho_2_loss: 0.0633 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 7/15\n",
      "98/98 [==============================] - 12s 122ms/step - loss: 0.0625 - ortho_2_loss: 0.0625 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 8/15\n",
      "98/98 [==============================] - 12s 122ms/step - loss: 0.0613 - ortho_2_loss: 0.0613 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 9/15\n",
      "98/98 [==============================] - 12s 122ms/step - loss: 0.0604 - ortho_2_loss: 0.0604 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 10/15\n",
      "98/98 [==============================] - 12s 125ms/step - loss: 0.0599 - ortho_2_loss: 0.0599 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 11/15\n",
      "98/98 [==============================] - 12s 127ms/step - loss: 0.0587 - ortho_2_loss: 0.0587 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 12/15\n",
      "98/98 [==============================] - 12s 124ms/step - loss: 0.0580 - ortho_2_loss: 0.0580 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 13/15\n",
      "98/98 [==============================] - 12s 126ms/step - loss: 0.0577 - ortho_2_loss: 0.0577 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 14/15\n",
      "98/98 [==============================] - 12s 127ms/step - loss: 0.0566 - ortho_2_loss: 0.0566 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 15/15\n",
      "98/98 [==============================] - 12s 126ms/step - loss: 0.0559 - ortho_2_loss: 0.0559 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohairshafi/miniforge3/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:1692: ConvergenceWarning: Maximum number of iterations 4000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x4dc596680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x4dc596680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x4dc596710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x4dc596710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x4dc5967a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x4dc5967a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:17:12.387717: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 16s 156ms/step - loss: 584.9823 - ortho_2_loss: 69.3379 - tf.math.reduce_sum_17_loss: 3.0719 - tf.math.multiply_35_loss: 512.5725\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 14s 148ms/step - loss: 361.7868 - ortho_2_loss: 69.3762 - tf.math.reduce_sum_17_loss: 0.7314 - tf.math.multiply_35_loss: 291.6791\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 14s 143ms/step - loss: 281.6887 - ortho_2_loss: 69.4281 - tf.math.reduce_sum_17_loss: 0.6219 - tf.math.multiply_35_loss: 211.6386\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 14s 139ms/step - loss: 235.6213 - ortho_2_loss: 69.4953 - tf.math.reduce_sum_17_loss: 0.3366 - tf.math.multiply_35_loss: 165.7894\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 14s 138ms/step - loss: 205.7632 - ortho_2_loss: 69.5782 - tf.math.reduce_sum_17_loss: 0.2014 - tf.math.multiply_35_loss: 135.9835\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 13s 134ms/step - loss: 185.0595 - ortho_2_loss: 69.6709 - tf.math.reduce_sum_17_loss: 0.1339 - tf.math.multiply_35_loss: 115.2546\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 14s 138ms/step - loss: 168.9425 - ortho_2_loss: 69.7846 - tf.math.reduce_sum_17_loss: 0.0819 - tf.math.multiply_35_loss: 99.0759\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 13s 135ms/step - loss: 157.0775 - ortho_2_loss: 69.9055 - tf.math.reduce_sum_17_loss: 0.0674 - tf.math.multiply_35_loss: 87.1046\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 14s 140ms/step - loss: 147.4852 - ortho_2_loss: 70.0370 - tf.math.reduce_sum_17_loss: 0.0515 - tf.math.multiply_35_loss: 77.3967\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 13s 136ms/step - loss: 139.8433 - ortho_2_loss: 70.1840 - tf.math.reduce_sum_17_loss: 0.0530 - tf.math.multiply_35_loss: 69.6064\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 14s 141ms/step - loss: 133.6877 - ortho_2_loss: 70.3184 - tf.math.reduce_sum_17_loss: 0.0649 - tf.math.multiply_35_loss: 63.3045\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 14s 142ms/step - loss: 128.6392 - ortho_2_loss: 70.4556 - tf.math.reduce_sum_17_loss: 0.0762 - tf.math.multiply_35_loss: 58.1074\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 14s 143ms/step - loss: 124.3753 - ortho_2_loss: 70.6010 - tf.math.reduce_sum_17_loss: 0.0962 - tf.math.multiply_35_loss: 53.6781\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 14s 138ms/step - loss: 120.8740 - ortho_2_loss: 70.7061 - tf.math.reduce_sum_17_loss: 0.1213 - tf.math.multiply_35_loss: 50.0465\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 14s 138ms/step - loss: 117.8548 - ortho_2_loss: 70.8055 - tf.math.reduce_sum_17_loss: 0.1524 - tf.math.multiply_35_loss: 46.8969\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 13s 136ms/step - loss: 115.4529 - ortho_2_loss: 70.9102 - tf.math.reduce_sum_17_loss: 0.1866 - tf.math.multiply_35_loss: 44.3561\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 13s 137ms/step - loss: 113.4314 - ortho_2_loss: 70.9368 - tf.math.reduce_sum_17_loss: 0.2248 - tf.math.multiply_35_loss: 42.2698\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 14s 139ms/step - loss: 111.6115 - ortho_2_loss: 70.9691 - tf.math.reduce_sum_17_loss: 0.2648 - tf.math.multiply_35_loss: 40.3776\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 13s 136ms/step - loss: 110.3054 - ortho_2_loss: 71.0453 - tf.math.reduce_sum_17_loss: 0.3054 - tf.math.multiply_35_loss: 38.9547\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 13s 135ms/step - loss: 108.8628 - ortho_2_loss: 71.0090 - tf.math.reduce_sum_17_loss: 0.3486 - tf.math.multiply_35_loss: 37.5051\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 14s 139ms/step - loss: 107.6434 - ortho_2_loss: 71.0030 - tf.math.reduce_sum_17_loss: 0.3940 - tf.math.multiply_35_loss: 36.2464\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 13s 137ms/step - loss: 106.6733 - ortho_2_loss: 71.0539 - tf.math.reduce_sum_17_loss: 0.4396 - tf.math.multiply_35_loss: 35.1798\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 13s 135ms/step - loss: 105.4607 - ortho_2_loss: 70.9718 - tf.math.reduce_sum_17_loss: 0.4877 - tf.math.multiply_35_loss: 34.0013\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 13s 136ms/step - loss: 104.5443 - ortho_2_loss: 70.9428 - tf.math.reduce_sum_17_loss: 0.5356 - tf.math.multiply_35_loss: 33.0658\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 14s 139ms/step - loss: 103.8115 - ortho_2_loss: 70.9877 - tf.math.reduce_sum_17_loss: 0.5801 - tf.math.multiply_35_loss: 32.2438\n",
      "Epoch 26/50\n",
      "28/98 [=======>......................] - ETA: 10s - loss: 102.9754 - ortho_2_loss: 70.7139 - tf.math.reduce_sum_17_loss: 0.6125 - tf.math.multiply_35_loss: 31.6490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [17:22<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = './data/email.pkl'\n",
    "run_count = 1\n",
    "hyp_key = 'hyp_email'\n",
    "outfile = './email_line.pkl'\n",
    "\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-g\", \"--graph_path\", required = True, help = 'Path to an nx.Graph object stored as a .pkl file')\n",
    "# ap.add_argument(\"-r\", \"--run_count\", required = True, help = \"Number of iterations for the experiment\", default = 1)\n",
    "# ap.add_argument(\"-k\", \"--hyp_key\", required = True, help = \"Key to index the hyperparameter json file\")\n",
    "# ap.add_argument(\"-o\", \"--outfile\", required = True, help = \"File name to save results into\")\n",
    "\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "# filename = args['graph_path']\n",
    "# run_count = args['run_count']\n",
    "# hyp_key = args['hyp_key']\n",
    "# outfile = args['outfile']\n",
    "\n",
    "#################################\n",
    "######### Read In Graph #########\n",
    "#################################\n",
    "with open(filename, 'rb') as file: \n",
    "    graph_dict = pkl.load(file)\n",
    "    \n",
    "graph = nx.Graph(nx.to_numpy_array(graph_dict['graph']))    \n",
    "graph = nx.Graph(nx.to_numpy_array(graph))\n",
    "\n",
    "\n",
    "#################################\n",
    "#### Generate Sense Features ####\n",
    "#################################\n",
    "sense_feat_dict, sense_features = get_sense_features(graph, ppr_flag = 'std')\n",
    "\n",
    "uncorrelated_feats = ['Degree',\n",
    "                    'Clustering Coefficient',\n",
    "                    'Personalized Page Rank - Standard Deviation',\n",
    "                    'Average Neighbor Degree',\n",
    "                    'Average Neighbor Clustering',\n",
    "                    'Eccentricity',\n",
    "                    'Katz Centrality']\n",
    "sense_features = sense_features[:, [list(sense_feat_dict).index(feat) for feat in uncorrelated_feats]]\n",
    "sense_feat_dict = {feat : idx for idx, feat in enumerate(uncorrelated_feats)}\n",
    "\n",
    "#################################\n",
    "######## Hyperparameters ########\n",
    "#################################\n",
    "\n",
    "# Define static ones to override or read in from a file\n",
    "\n",
    "if hyp_key == '':\n",
    "    hyp = {'line' : {'alpha' : 0.1, \n",
    "                     'ortho' : 0, \n",
    "                     'sparse' : 0, \n",
    "                     'epochs' : 15, \n",
    "                     'batch_size' : 1024, \n",
    "                     'lr' : 1e-3}, \n",
    "\n",
    "          'line+xm' : {'alpha' : 100, \n",
    "                      'ortho' : 10, \n",
    "                      'sparse' : 10, \n",
    "                      'epochs' : 50, \n",
    "                      'batch_size' : 1024, \n",
    "                      'lr' : 5e-4}}\n",
    "else: \n",
    "    with open('scripts/hyp.json', 'r') as file: \n",
    "        hyp_file = json.load(file)\n",
    "        hyp = hyp_file[hyp_key]\n",
    "\n",
    "\n",
    "#################################\n",
    "######## Run Experiment #########\n",
    "#################################\n",
    "\n",
    "dimensions = [16, 32, 64, 256, 512]\n",
    "results = {d : {} for d in dimensions}\n",
    "run_time = []\n",
    "\n",
    "for run_idx in tqdm(range(run_count)):\n",
    "    \n",
    "    run_start = time.time()\n",
    "\n",
    "    for d in dimensions: \n",
    "    \n",
    "        # Embed \n",
    "        \n",
    "        # Standard LINE\n",
    "        line_start = time.time()\n",
    "        line = LINE(graph, \n",
    "                embedding_size = d,\n",
    "                sense_features = sense_features,\n",
    "                alpha = hyp['line']['alpha'], \n",
    "                ortho = hyp['line']['ortho'], \n",
    "                sparse = hyp['line']['sparse'],\n",
    "                learning_rate =  hyp['line']['lr'],\n",
    "                order = 'second', \n",
    "                batch_size = hyp['line']['batch_size'])\n",
    "\n",
    "        history = line.train(epochs = hyp['line']['epochs'])\n",
    "\n",
    "        e = line.get_embeddings()\n",
    "        embed_og = np.array([e[node_name] for node_name in graph.nodes()])\n",
    "        embed_og = (embed_og - np.min(embed_og)) / np.ptp(embed_og)\n",
    "        line_time = (time.time() - line_start) / hyp['line']['epochs']\n",
    "\n",
    "\n",
    "        feature_dict_og = find_feature_membership(input_embed = embed_og,\n",
    "                                                            embed_name = 'LINE',\n",
    "                                                            sense_features = sense_features,\n",
    "                                                            sense_feat_dict = sense_feat_dict,\n",
    "                                                            top_k = 8,\n",
    "                                                            solver = 'nmf')\n",
    "\n",
    "        explain_og = feature_dict_og['explain_norm']\n",
    "        error_og = sense_features * np.log((sense_features + 1e-10) / ((embed_og @ feature_dict_og['explain_norm']) + 1e-10)) - sense_features + (embed_og @ feature_dict_og['explain_norm'])\n",
    "        explain_og = (explain_og - np.min(explain_og)) / np.ptp(explain_og)\n",
    "        \n",
    "        # LINE+XM\n",
    "        line_plus_start = time.time()\n",
    "        line_plus = LINE(graph, \n",
    "                        embedding_size = d,\n",
    "                        sense_features = sense_features,\n",
    "                        alpha = hyp['line+xm']['alpha'], \n",
    "                        ortho = hyp['line+xm']['ortho'], \n",
    "                        sparse = hyp['line+xm']['sparse'],\n",
    "                        learning_rate =  hyp['line+xm']['lr'],\n",
    "                        order = 'second', \n",
    "                        batch_size = hyp['line+xm']['batch_size'])\n",
    "\n",
    "        history = line_plus.train(epochs = hyp['line+xm']['epochs'])\n",
    "\n",
    "        e = line_plus.get_embeddings()\n",
    "        embed_plus = np.array([e[node_name] for node_name in graph.nodes()])\n",
    "        embed_plus = (embed_plus - np.min(embed_plus)) / np.ptp(embed_plus)\n",
    "        line_plus_time = (time.time() - line_plus_start) / hyp['line+xm']['epochs']\n",
    "\n",
    "        feature_dict_plus = find_feature_membership(input_embed = embed_plus,\n",
    "                                                            embed_name = 'LINE+XM',\n",
    "                                                            sense_features = sense_features,\n",
    "                                                            sense_feat_dict = sense_feat_dict,\n",
    "                                                            top_k = 8,\n",
    "                                                            solver = 'nmf')\n",
    "\n",
    "        explain_plus = feature_dict_plus['explain_norm']\n",
    "        error_plus = sense_features * np.log((sense_features + 1e-10) / ((embed_plus @ feature_dict_plus['explain_norm']) + 1e-10)) - sense_features + (embed_plus @ feature_dict_plus['explain_norm'])\n",
    "        explain_plus = (explain_plus - np.min(explain_plus)) / np.ptp(explain_plus)\n",
    "\n",
    "        # Generate Node Explanations\n",
    "        Y_og = embed_og\n",
    "        sense_mat = tf.einsum('ij, ik -> ijk', Y_og, sense_features)\n",
    "        Y_og_norm = tf.linalg.diag_part(tf.matmul(Y_og, Y_og, transpose_b = True), k = 0)\n",
    "        sense_norm = tf.linalg.diag_part(tf.matmul(sense_features, sense_features, transpose_b = True), k = 0)\n",
    "        norm = Y_og_norm * tf.cast(sense_norm, tf.float32)\n",
    "        D_og = tf.transpose(tf.transpose(sense_mat) / norm)\n",
    "\n",
    "\n",
    "        Y_plus = embed_plus\n",
    "        sense_mat = tf.einsum('ij, ik -> ijk', Y_plus, sense_features)\n",
    "        Y_plus_norm = tf.linalg.diag_part(tf.matmul(Y_plus, Y_plus, transpose_b = True), k = 0)\n",
    "        sense_norm = tf.linalg.diag_part(tf.matmul(sense_features, sense_features, transpose_b = True), k = 0)\n",
    "        norm = Y_plus_norm * tf.cast(sense_norm, tf.float32)\n",
    "        D_plus = tf.transpose(tf.transpose(sense_mat) / norm)\n",
    "\n",
    "        norm_og = [np.linalg.norm(D_og[node, :, :], ord = 'nuc') for node in range(len(graph))]\n",
    "        norm_plus = [np.linalg.norm(D_plus[node, :, :], ord = 'nuc') for node in range(len(graph))]\n",
    "        \n",
    "        try:\n",
    "            results[d]['norm_og'].append(norm_og)\n",
    "            results[d]['norm_plus'].append(norm_plus)\n",
    "            results[d]['explain_og_norm'].append(explain_og_norm)\n",
    "            results[d]['explain_plus_norm'].append(explain_plus_norm)\n",
    "            results[d]['line_time'].append(line_time)\n",
    "            results[d]['line+xm_time'].append(line_plus_time)\n",
    "            results[d]['error_og'].append(error_og)\n",
    "            results[d]['error_plus'].append(error_plus)\n",
    "            \n",
    "        except: \n",
    "            results[d]['norm_og'] = [norm_og]\n",
    "            results[d]['norm_plus'] = [norm_plus]\n",
    "            results[d]['explain_og_norm'] = [explain_og_norm]\n",
    "            results[d]['explain_plus_norm'] = [explain_plus_norm]\n",
    "            results[d]['line_time'] = [line_time]\n",
    "            results[d]['line+xm_time'] = [line_plus_time]\n",
    "            results[d]['error_og'] = [error_og]\n",
    "            results[d]['error_plus'] = [error_plus]\n",
    "            \n",
    "        results[d]['embed_og'] = embed_og\n",
    "        results[d]['embed_plus'] = embed_plus\n",
    "    \n",
    "    with open(outfile, 'wb') as file: \n",
    "        pkl.dump(results, file)\n",
    "        \n",
    "    with open(outfile, 'wb') as file: \n",
    "        pkl.dump(results, file)\n",
    "\n",
    "    run_time.append(time.time() - run_start)\n",
    "\n",
    "    with open(outfile + '_progress.txt', 'w') as file: \n",
    "        string = 'Current Run : ' + str(run_idx)\n",
    "        string += '\\nLast Iteration Time : ' + str(run_time[-1]) + 's'\n",
    "        string += '\\nAverage Iteration Time : ' + str(np.mean(run_time)) + 's'\n",
    "        string += '\\nEstimated Time Left : ' + str(np.mean(run_time) * (run_count - run_idx)) + 's'\n",
    "        file.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861260f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74a46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
