{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e23f7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3e83b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4998501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './email.pkl'\n",
    "run_count = 1\n",
    "hyp_key = 'hyp_email'\n",
    "outfile = './email_test.pkl'\n",
    "\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-g\", \"--graph_path\", required = True, help = 'Path to an nx.Graph object stored as a .pkl file')\n",
    "# ap.add_argument(\"-r\", \"--run_count\", required = True, help = \"Number of iterations for the experiment\", default = 1)\n",
    "# ap.add_argument(\"-k\", \"--hyp_key\", required = True, help = \"Key to index the hyperparameter json file\")\n",
    "# ap.add_argument(\"-o\", \"--outfile\", required = True, help = \"File name to save results into\")\n",
    "\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "# filename = args['graph_path']\n",
    "# run_count = args['run_count']\n",
    "# hyp_key = args['hyp_key']\n",
    "# outfile = args['outfile']\n",
    "\n",
    "#################################\n",
    "######### Read In Graph #########\n",
    "#################################\n",
    "with open(filename, 'rb') as file: \n",
    "    graph_dict = pkl.load(file)\n",
    "    \n",
    "graph = nx.Graph(nx.to_numpy_array(graph_dict['graph']))    \n",
    "graph = nx.Graph(nx.to_numpy_array(graph))\n",
    "\n",
    "\n",
    "#################################\n",
    "#### Generate Sense Features ####\n",
    "#################################\n",
    "sense_feat_dict, sense_features = get_sense_features(graph, ppr_flag = 'std')\n",
    "\n",
    "uncorrelated_feats = ['Degree',\n",
    "                    'Clustering Coefficient',\n",
    "                    'Personalized Page Rank - Standard Deviation',\n",
    "                    'Average Neighbor Degree',\n",
    "                    'Average Neighbor Clustering',\n",
    "                    'Eccentricity',\n",
    "                    'Katz Centrality']\n",
    "sense_features = sense_features[:, [list(sense_feat_dict).index(feat) for feat in uncorrelated_feats]]\n",
    "sense_feat_dict = {feat : idx for idx, feat in enumerate(uncorrelated_feats)}\n",
    "\n",
    "#################################\n",
    "######## Hyperparameters ########\n",
    "#################################\n",
    "\n",
    "# Define static ones to override or read in from a file\n",
    "\n",
    "if hyp_key == '':\n",
    "    hyp = {'sdne' : {'alpha' : 0.1, \n",
    "                     'beta' : 10, \n",
    "                     'gamma' : 0, \n",
    "                     'delta' : 0, \n",
    "                     'epochs' : 200, \n",
    "                     'batch_size' : 1024, \n",
    "                     'lr' : 1e-3}, \n",
    "\n",
    "          'sdne+xm' : {'alpha' : 1, \n",
    "                      'beta' : 1, \n",
    "                      'gamma' : 10, \n",
    "                      'delta' : 10, \n",
    "                      'epochs' : 400, \n",
    "                      'batch_size' : 1024, \n",
    "                      'lr' : 5e-4}}\n",
    "else: \n",
    "    with open('scripts/hyp.json', 'r') as file: \n",
    "        hyp_file = json.load(file)\n",
    "        hyp = hyp_file[hyp_key]\n",
    "\n",
    "\n",
    "#################################\n",
    "######## Run Experiment #########\n",
    "#################################\n",
    "\n",
    "dimensions = [16, 32, 64, 256, 512]\n",
    "results = {d : {} for d in dimensions}\n",
    "\n",
    "for run_idx in tqdm(range(run_count)):\n",
    "    \n",
    "    for d in dimensions: \n",
    "    \n",
    "        # Embed \n",
    "        \n",
    "        # Standard SDNE\n",
    "        sdne = SDNE_plus(graph, \n",
    "                          hidden_size = [32, d], \n",
    "                          lr = hyp['sdne']['lr'],\n",
    "                          sense_features = sense_features.astype(np.float32),\n",
    "                          alpha = hyp['sdne']['alpha'], \n",
    "                          beta = hyp['sdne']['beta'], \n",
    "                          gamma = hyp['sdne']['gamma'], \n",
    "                          delta = hyp['sdne']['delta'])\n",
    "        history = sdne.train(epochs = hyp['sdne']['epochs'], batch_size = hyp['sdne']['batch_size'])\n",
    "        e = sdne.get_embeddings()\n",
    "        embed_og = np.array([e[node_name] for node_name in graph.nodes()])\n",
    "        embed_og = (embed_og - np.min(embed_og)) / np.ptp(embed_og)\n",
    "\n",
    "        # SDNE+XM\n",
    "        sdne_plus = SDNE_plus(graph, \n",
    "                                  hidden_size = [32, d], \n",
    "                                  lr = hyp['sdne+xm']['lr'],\n",
    "                                  sense_features = sense_features.astype(np.float32),\n",
    "                                  alpha = hyp['sdne+xm']['alpha'], \n",
    "                                  beta = hyp['sdne+xm']['beta'], \n",
    "                                  gamma = hyp['sdne+xm']['gamma'], \n",
    "                                  delta = hyp['sdne+xm']['delta'])\n",
    "\n",
    "        sdne_plus.model.set_weights(sdne.model.get_weights())\n",
    "        history = sdne_plus.train(epochs = hyp['sdne+xm']['epochs'], batch_size = hyp['sdne+xm']['batch_size'])\n",
    "        e = sdne_plus.get_embeddings()\n",
    "        embed_plus = np.array([e[node_name] for node_name in graph.nodes()])\n",
    "        embed_plus = (embed_plus - np.min(embed_plus)) / np.ptp(embed_plus)\n",
    "        \n",
    "        # Generate Graph Explanations and Save\n",
    "        feature_dict_og = find_feature_membership(input_embed = embed_og,\n",
    "                                                    embed_name = 'SDNE',\n",
    "                                                    sense_features = sense_features,\n",
    "                                                    sense_feat_dict = sense_feat_dict,\n",
    "                                                    top_k = 8,\n",
    "                                                    solver = 'nmf')\n",
    "\n",
    "        explain_og = feature_dict_og['explain_norm']\n",
    "        explain_og = (explain_og - np.min(explain_og)) / np.ptp(explain_og)\n",
    "        explain_og_norm = np.linalg.norm(explain_og, ord = 'nuc')\n",
    "        \n",
    "        feature_dict_plus = find_feature_membership(input_embed = embed_plus,\n",
    "                                                            embed_name = 'SDNE+ Init',\n",
    "                                                            sense_features = sense_features,\n",
    "                                                            sense_feat_dict = sense_feat_dict,\n",
    "                                                            top_k = 8,\n",
    "                                                            solver = 'nmf')\n",
    "\n",
    "        explain_plus = feature_dict_plus['explain_norm']\n",
    "        explain_plus = (explain_plus - np.min(explain_plus)) / np.ptp(explain_plus)\n",
    "        explain_plus_norm = np.linalg.norm(explain_plus, ord = 'nuc')\n",
    "\n",
    "        # Generate Node Explanations\n",
    "        Y_og = embed_og\n",
    "        sense_mat = tf.einsum('ij, ik -> ijk', Y_og, sense_features)\n",
    "        Y_og_norm = tf.linalg.diag_part(tf.matmul(Y_og, Y_og, transpose_b = True), k = 0)\n",
    "        sense_norm = tf.linalg.diag_part(tf.matmul(sense_features, sense_features, transpose_b = True), k = 0)\n",
    "        norm = Y_og_norm * tf.cast(sense_norm, tf.float32)\n",
    "        D_og = tf.transpose(tf.transpose(sense_mat) / norm)\n",
    "\n",
    "\n",
    "        Y_plus = embed_plus\n",
    "        sense_mat = tf.einsum('ij, ik -> ijk', Y_plus, sense_features)\n",
    "        Y_plus_norm = tf.linalg.diag_part(tf.matmul(Y_plus, Y_plus, transpose_b = True), k = 0)\n",
    "        sense_norm = tf.linalg.diag_part(tf.matmul(sense_features, sense_features, transpose_b = True), k = 0)\n",
    "        norm = Y_plus_norm * tf.cast(sense_norm, tf.float32)\n",
    "        D_plus = tf.transpose(tf.transpose(sense_mat) / norm)\n",
    "\n",
    "        norm_og = [np.linalg.norm(D_og[node, :, :], ord = 'nuc') for node in range(len(graph))]\n",
    "        norm_plus = [np.linalg.norm(D_plus[node, :, :], ord = 'nuc') for node in range(len(graph))]\n",
    "        \n",
    "        try:\n",
    "            results[d]['norm_og'].append(norm_og)\n",
    "            results[d]['norm_plus'].append(norm_plus)\n",
    "            results[d]['explain_og_norm'].append(explain_og_norm)\n",
    "            results[d]['explain_plus_norm'].append(explain_plus_norm)\n",
    "            \n",
    "        except: \n",
    "            results[d]['norm_og'] = [norm_og]\n",
    "            results[d]['norm_plus'] = [norm_plus]\n",
    "            results[d]['explain_og_norm'] = [explain_og_norm]\n",
    "            results[d]['explain_plus_norm'] = [explain_plus_norm]\n",
    "            \n",
    "        results[d]['embed_og'] = embed_og\n",
    "        results[d]['embed_plus'] = embed_plus\n",
    "    \n",
    "    with open(outfile, 'wb') as file: \n",
    "        pkl.dump(results, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3af0218",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "565ae61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Personalized Page Rank...                     \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "986it [00:22, 44.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Node Betweenness...                           \r",
      "Calculating Number Of Edges In Ego Nets...                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohairshafi/miniforge3/lib/python3.10/site-packages/networkx/algorithms/centrality/katz.py:325: FutureWarning: adjacency_matrix will return a scipy.sparse array instead of a matrix in Networkx 3.0.\n",
      "  A = nx.adjacency_matrix(G, nodelist=nodelist, weight=weight).todense().T\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Structural Hole Constraint Scores...         \r",
      "Calculating Degree Centrality...                         \r",
      "Calculating Eigen Centrality...                          \r",
      "Calculating Katz Centrality...                           \r",
      "Normalizing Features Between 0 And 1...                   \r",
      "Done                                                      \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                     | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2be0ca950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2be0ca950> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2be0ca710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2be0ca710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2be0ca4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2be0ca4d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:05:35.975029: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 3s 22ms/step - loss: 0.0686 - ortho_2_loss: 0.0686 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 2/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0670 - ortho_2_loss: 0.0670 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 3/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0654 - ortho_2_loss: 0.0654 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 4/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0642 - ortho_2_loss: 0.0642 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 5/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0627 - ortho_2_loss: 0.0627 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 6/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0615 - ortho_2_loss: 0.0615 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 7/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0607 - ortho_2_loss: 0.0607 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 8/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0593 - ortho_2_loss: 0.0593 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 9/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0583 - ortho_2_loss: 0.0583 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 10/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0578 - ortho_2_loss: 0.0578 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 11/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0565 - ortho_2_loss: 0.0565 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 12/15\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 0.0557 - ortho_2_loss: 0.0557 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 13/15\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 0.0555 - ortho_2_loss: 0.0555 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 14/15\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 0.0543 - ortho_2_loss: 0.0543 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 15/15\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 0.0537 - ortho_2_loss: 0.0537 - tf.math.reduce_sum_10_loss: 0.0000e+00 - tf.math.multiply_21_loss: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2bd55e440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2bd55e440> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2bd55dc60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2bd55dc60> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2bd55d990> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2bd55d990> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:06:00.095603: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 3s 20ms/step - loss: 780.2347 - ortho_2_loss: 69.3413 - tf.math.reduce_sum_11_loss: 141.9788 - tf.math.multiply_23_loss: 568.9145\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 379.4205 - ortho_2_loss: 69.3726 - tf.math.reduce_sum_11_loss: 4.3295 - tf.math.multiply_23_loss: 305.7186\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 288.6990 - ortho_2_loss: 69.4214 - tf.math.reduce_sum_11_loss: 2.2049 - tf.math.multiply_23_loss: 217.0727\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 237.8753 - ortho_2_loss: 69.4875 - tf.math.reduce_sum_11_loss: 1.4923 - tf.math.multiply_23_loss: 166.8955\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 204.0805 - ortho_2_loss: 69.5763 - tf.math.reduce_sum_11_loss: 0.8962 - tf.math.multiply_23_loss: 133.6080\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 183.3327 - ortho_2_loss: 69.6694 - tf.math.reduce_sum_11_loss: 0.7633 - tf.math.multiply_23_loss: 112.9001\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 166.2986 - ortho_2_loss: 69.7859 - tf.math.reduce_sum_11_loss: 0.5118 - tf.math.multiply_23_loss: 96.0010\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 154.6747 - ortho_2_loss: 69.9091 - tf.math.reduce_sum_11_loss: 0.4106 - tf.math.multiply_23_loss: 84.3550\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 144.7557 - ortho_2_loss: 70.0492 - tf.math.reduce_sum_11_loss: 0.3320 - tf.math.multiply_23_loss: 74.3745\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 137.8974 - ortho_2_loss: 70.1825 - tf.math.reduce_sum_11_loss: 0.3128 - tf.math.multiply_23_loss: 67.4023\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 131.4819 - ortho_2_loss: 70.3301 - tf.math.reduce_sum_11_loss: 0.2669 - tf.math.multiply_23_loss: 60.8848\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 126.7352 - ortho_2_loss: 70.4663 - tf.math.reduce_sum_11_loss: 0.2427 - tf.math.multiply_23_loss: 56.0262\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 122.6697 - ortho_2_loss: 70.6194 - tf.math.reduce_sum_11_loss: 0.2379 - tf.math.multiply_23_loss: 51.8124\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 119.0892 - ortho_2_loss: 70.7391 - tf.math.reduce_sum_11_loss: 0.2373 - tf.math.multiply_23_loss: 48.1128\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 116.1673 - ortho_2_loss: 70.8623 - tf.math.reduce_sum_11_loss: 0.2362 - tf.math.multiply_23_loss: 45.0688\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 113.6046 - ortho_2_loss: 70.9982 - tf.math.reduce_sum_11_loss: 0.2526 - tf.math.multiply_23_loss: 42.3538\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 111.3640 - ortho_2_loss: 71.0534 - tf.math.reduce_sum_11_loss: 0.2754 - tf.math.multiply_23_loss: 40.0352\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 109.3411 - ortho_2_loss: 71.1188 - tf.math.reduce_sum_11_loss: 0.3035 - tf.math.multiply_23_loss: 37.9188\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 107.5168 - ortho_2_loss: 71.2037 - tf.math.reduce_sum_11_loss: 0.3398 - tf.math.multiply_23_loss: 35.9734\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 105.9335 - ortho_2_loss: 71.1553 - tf.math.reduce_sum_11_loss: 0.3918 - tf.math.multiply_23_loss: 34.3864\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 104.5056 - ortho_2_loss: 71.1352 - tf.math.reduce_sum_11_loss: 0.4468 - tf.math.multiply_23_loss: 32.9236\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 103.2812 - ortho_2_loss: 71.1588 - tf.math.reduce_sum_11_loss: 0.5067 - tf.math.multiply_23_loss: 31.6157\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 101.9042 - ortho_2_loss: 70.9823 - tf.math.reduce_sum_11_loss: 0.5911 - tf.math.multiply_23_loss: 30.3308\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 100.7171 - ortho_2_loss: 70.8551 - tf.math.reduce_sum_11_loss: 0.6749 - tf.math.multiply_23_loss: 29.1870\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 99.7537 - ortho_2_loss: 70.8222 - tf.math.reduce_sum_11_loss: 0.7626 - tf.math.multiply_23_loss: 28.1689\n",
      "Epoch 26/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 98.5185 - ortho_2_loss: 70.4958 - tf.math.reduce_sum_11_loss: 0.8629 - tf.math.multiply_23_loss: 27.1598\n",
      "Epoch 27/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 97.5353 - ortho_2_loss: 70.3484 - tf.math.reduce_sum_11_loss: 0.9663 - tf.math.multiply_23_loss: 26.2206\n",
      "Epoch 28/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 96.6270 - ortho_2_loss: 70.2330 - tf.math.reduce_sum_11_loss: 1.0781 - tf.math.multiply_23_loss: 25.3159\n",
      "Epoch 29/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 95.5708 - ortho_2_loss: 69.8442 - tf.math.reduce_sum_11_loss: 1.1809 - tf.math.multiply_23_loss: 24.5457\n",
      "Epoch 30/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 94.6749 - ortho_2_loss: 69.5800 - tf.math.reduce_sum_11_loss: 1.2892 - tf.math.multiply_23_loss: 23.8057\n",
      "Epoch 31/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 93.9856 - ortho_2_loss: 69.5182 - tf.math.reduce_sum_11_loss: 1.3971 - tf.math.multiply_23_loss: 23.0704\n",
      "Epoch 32/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 92.8414 - ortho_2_loss: 69.0165 - tf.math.reduce_sum_11_loss: 1.5066 - tf.math.multiply_23_loss: 22.3183\n",
      "Epoch 33/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 92.1299 - ortho_2_loss: 68.7617 - tf.math.reduce_sum_11_loss: 1.5945 - tf.math.multiply_23_loss: 21.7737\n",
      "Epoch 34/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 91.4978 - ortho_2_loss: 68.7216 - tf.math.reduce_sum_11_loss: 1.6946 - tf.math.multiply_23_loss: 21.0816\n",
      "Epoch 35/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 90.5595 - ortho_2_loss: 68.1931 - tf.math.reduce_sum_11_loss: 1.7871 - tf.math.multiply_23_loss: 20.5793\n",
      "Epoch 36/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 89.7815 - ortho_2_loss: 67.9065 - tf.math.reduce_sum_11_loss: 1.8643 - tf.math.multiply_23_loss: 20.0106\n",
      "Epoch 37/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 89.3000 - ortho_2_loss: 67.8870 - tf.math.reduce_sum_11_loss: 1.9592 - tf.math.multiply_23_loss: 19.4538\n",
      "Epoch 38/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 88.2864 - ortho_2_loss: 67.3075 - tf.math.reduce_sum_11_loss: 2.0412 - tf.math.multiply_23_loss: 18.9377\n",
      "Epoch 39/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 87.7300 - ortho_2_loss: 67.0506 - tf.math.reduce_sum_11_loss: 2.1061 - tf.math.multiply_23_loss: 18.5733\n",
      "Epoch 40/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 87.2720 - ortho_2_loss: 67.1120 - tf.math.reduce_sum_11_loss: 2.1647 - tf.math.multiply_23_loss: 17.9953\n",
      "Epoch 41/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 86.4004 - ortho_2_loss: 66.4893 - tf.math.reduce_sum_11_loss: 2.2240 - tf.math.multiply_23_loss: 17.6872\n",
      "Epoch 42/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 85.8835 - ortho_2_loss: 66.2918 - tf.math.reduce_sum_11_loss: 2.2719 - tf.math.multiply_23_loss: 17.3198\n",
      "Epoch 43/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 85.6873 - ortho_2_loss: 66.4193 - tf.math.reduce_sum_11_loss: 2.3105 - tf.math.multiply_23_loss: 16.9575\n",
      "Epoch 44/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 84.8246 - ortho_2_loss: 65.8042 - tf.math.reduce_sum_11_loss: 2.3658 - tf.math.multiply_23_loss: 16.6546\n",
      "Epoch 45/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 84.2936 - ortho_2_loss: 65.5671 - tf.math.reduce_sum_11_loss: 2.3915 - tf.math.multiply_23_loss: 16.3350\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 1s 14ms/step - loss: 84.2397 - ortho_2_loss: 65.7772 - tf.math.reduce_sum_11_loss: 2.4270 - tf.math.multiply_23_loss: 16.0354\n",
      "Epoch 47/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 83.3559 - ortho_2_loss: 65.1326 - tf.math.reduce_sum_11_loss: 2.4605 - tf.math.multiply_23_loss: 15.7628\n",
      "Epoch 48/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 82.8866 - ortho_2_loss: 64.8934 - tf.math.reduce_sum_11_loss: 2.4877 - tf.math.multiply_23_loss: 15.5055\n",
      "Epoch 49/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 82.9342 - ortho_2_loss: 65.1700 - tf.math.reduce_sum_11_loss: 2.5117 - tf.math.multiply_23_loss: 15.2524\n",
      "Epoch 50/50\n",
      "98/98 [==============================] - 1s 14ms/step - loss: 82.0378 - ortho_2_loss: 64.4720 - tf.math.reduce_sum_11_loss: 2.5352 - tf.math.multiply_23_loss: 15.0306\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2bdb2b2e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2bdb2b2e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2bdb28ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2bdb28ee0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2bdb2a3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2bdb2a3b0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:07:46.045346: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 3s 24ms/step - loss: 0.0686 - ortho_2_loss: 0.0686 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 2/15\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.0671 - ortho_2_loss: 0.0671 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 3/15\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 0.0655 - ortho_2_loss: 0.0655 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 4/15\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 0.0643 - ortho_2_loss: 0.0643 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 5/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0629 - ortho_2_loss: 0.0629 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 6/15\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 0.0616 - ortho_2_loss: 0.0616 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 7/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0608 - ortho_2_loss: 0.0608 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 8/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0594 - ortho_2_loss: 0.0594 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 9/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0584 - ortho_2_loss: 0.0584 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 10/15\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.0580 - ortho_2_loss: 0.0580 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 11/15\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 0.0567 - ortho_2_loss: 0.0567 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 12/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0559 - ortho_2_loss: 0.0559 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 13/15\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 0.0557 - ortho_2_loss: 0.0557 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 14/15\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.0545 - ortho_2_loss: 0.0545 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 15/15\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 0.0538 - ortho_2_loss: 0.0538 - tf.math.reduce_sum_12_loss: 0.0000e+00 - tf.math.multiply_25_loss: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2bd55e320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2bd55e320> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2bd55dbd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2bd55dbd0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2bd55d510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2bd55d510> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:08:11.637698: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 3s 24ms/step - loss: 675.3688 - ortho_2_loss: 69.3348 - tf.math.reduce_sum_13_loss: 59.3795 - tf.math.multiply_27_loss: 546.6546\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 367.4493 - ortho_2_loss: 69.3722 - tf.math.reduce_sum_13_loss: 2.1345 - tf.math.multiply_27_loss: 295.9426\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 2s 18ms/step - loss: 279.4481 - ortho_2_loss: 69.4227 - tf.math.reduce_sum_13_loss: 1.3615 - tf.math.multiply_27_loss: 208.6639\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 234.2339 - ortho_2_loss: 69.4880 - tf.math.reduce_sum_13_loss: 0.9626 - tf.math.multiply_27_loss: 163.7832\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 203.8941 - ortho_2_loss: 69.5668 - tf.math.reduce_sum_13_loss: 0.6932 - tf.math.multiply_27_loss: 133.6341\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 2s 17ms/step - loss: 182.5330 - ortho_2_loss: 69.6610 - tf.math.reduce_sum_13_loss: 0.4728 - tf.math.multiply_27_loss: 112.3992\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 166.6379 - ortho_2_loss: 69.7739 - tf.math.reduce_sum_13_loss: 0.3478 - tf.math.multiply_27_loss: 96.5163\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 154.1031 - ortho_2_loss: 69.8984 - tf.math.reduce_sum_13_loss: 0.2695 - tf.math.multiply_27_loss: 83.9353\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 145.5388 - ortho_2_loss: 70.0253 - tf.math.reduce_sum_13_loss: 0.2462 - tf.math.multiply_27_loss: 75.2674\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 137.9593 - ortho_2_loss: 70.1693 - tf.math.reduce_sum_13_loss: 0.2039 - tf.math.multiply_27_loss: 67.5861\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 131.8694 - ortho_2_loss: 70.3027 - tf.math.reduce_sum_13_loss: 0.1866 - tf.math.multiply_27_loss: 61.3802\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 127.1360 - ortho_2_loss: 70.4424 - tf.math.reduce_sum_13_loss: 0.1785 - tf.math.multiply_27_loss: 56.5152\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 122.9268 - ortho_2_loss: 70.5870 - tf.math.reduce_sum_13_loss: 0.1824 - tf.math.multiply_27_loss: 52.1574\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 119.4902 - ortho_2_loss: 70.7028 - tf.math.reduce_sum_13_loss: 0.1868 - tf.math.multiply_27_loss: 48.6006\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 116.5415 - ortho_2_loss: 70.8029 - tf.math.reduce_sum_13_loss: 0.2061 - tf.math.multiply_27_loss: 45.5324\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 113.8320 - ortho_2_loss: 70.9409 - tf.math.reduce_sum_13_loss: 0.2236 - tf.math.multiply_27_loss: 42.6674\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 111.5619 - ortho_2_loss: 71.0012 - tf.math.reduce_sum_13_loss: 0.2516 - tf.math.multiply_27_loss: 40.3091\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 109.5187 - ortho_2_loss: 71.0605 - tf.math.reduce_sum_13_loss: 0.2852 - tf.math.multiply_27_loss: 38.1730\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 107.6207 - ortho_2_loss: 71.1511 - tf.math.reduce_sum_13_loss: 0.3282 - tf.math.multiply_27_loss: 36.1414\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 106.1419 - ortho_2_loss: 71.1222 - tf.math.reduce_sum_13_loss: 0.3747 - tf.math.multiply_27_loss: 34.6450\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 104.5504 - ortho_2_loss: 71.1173 - tf.math.reduce_sum_13_loss: 0.4281 - tf.math.multiply_27_loss: 33.0050\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 103.2720 - ortho_2_loss: 71.1392 - tf.math.reduce_sum_13_loss: 0.4956 - tf.math.multiply_27_loss: 31.6373\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 102.0771 - ortho_2_loss: 71.0138 - tf.math.reduce_sum_13_loss: 0.5627 - tf.math.multiply_27_loss: 30.5006\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 100.8245 - ortho_2_loss: 70.9093 - tf.math.reduce_sum_13_loss: 0.6400 - tf.math.multiply_27_loss: 29.2752\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 99.8300 - ortho_2_loss: 70.8957 - tf.math.reduce_sum_13_loss: 0.7251 - tf.math.multiply_27_loss: 28.2092\n",
      "Epoch 26/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 98.6542 - ortho_2_loss: 70.6011 - tf.math.reduce_sum_13_loss: 0.8166 - tf.math.multiply_27_loss: 27.2365\n",
      "Epoch 27/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 97.7070 - ortho_2_loss: 70.4775 - tf.math.reduce_sum_13_loss: 0.9129 - tf.math.multiply_27_loss: 26.3166\n",
      "Epoch 28/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 96.8818 - ortho_2_loss: 70.3965 - tf.math.reduce_sum_13_loss: 1.0132 - tf.math.multiply_27_loss: 25.4721\n",
      "Epoch 29/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 95.8739 - ortho_2_loss: 70.0344 - tf.math.reduce_sum_13_loss: 1.1118 - tf.math.multiply_27_loss: 24.7277\n",
      "Epoch 30/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 94.9736 - ortho_2_loss: 69.8064 - tf.math.reduce_sum_13_loss: 1.2070 - tf.math.multiply_27_loss: 23.9602\n",
      "Epoch 31/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 94.4088 - ortho_2_loss: 69.7845 - tf.math.reduce_sum_13_loss: 1.3022 - tf.math.multiply_27_loss: 23.3220\n",
      "Epoch 32/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 93.4843 - ortho_2_loss: 69.3567 - tf.math.reduce_sum_13_loss: 1.3938 - tf.math.multiply_27_loss: 22.7339\n",
      "Epoch 33/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 92.7443 - ortho_2_loss: 69.1303 - tf.math.reduce_sum_13_loss: 1.4792 - tf.math.multiply_27_loss: 22.1349\n",
      "Epoch 34/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 92.3247 - ortho_2_loss: 69.1465 - tf.math.reduce_sum_13_loss: 1.5560 - tf.math.multiply_27_loss: 21.6223\n",
      "Epoch 35/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 91.4030 - ortho_2_loss: 68.6775 - tf.math.reduce_sum_13_loss: 1.6426 - tf.math.multiply_27_loss: 21.0829\n",
      "Epoch 36/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 90.7776 - ortho_2_loss: 68.4275 - tf.math.reduce_sum_13_loss: 1.7230 - tf.math.multiply_27_loss: 20.6271\n",
      "Epoch 37/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 90.4719 - ortho_2_loss: 68.5191 - tf.math.reduce_sum_13_loss: 1.7812 - tf.math.multiply_27_loss: 20.1716\n",
      "Epoch 38/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 89.5912 - ortho_2_loss: 67.9999 - tf.math.reduce_sum_13_loss: 1.8571 - tf.math.multiply_27_loss: 19.7342\n",
      "Epoch 39/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 89.0089 - ortho_2_loss: 67.7869 - tf.math.reduce_sum_13_loss: 1.9163 - tf.math.multiply_27_loss: 19.3057\n",
      "Epoch 40/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 88.7344 - ortho_2_loss: 67.8781 - tf.math.reduce_sum_13_loss: 1.9718 - tf.math.multiply_27_loss: 18.8846\n",
      "Epoch 41/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 87.9668 - ortho_2_loss: 67.3652 - tf.math.reduce_sum_13_loss: 2.0325 - tf.math.multiply_27_loss: 18.5691\n",
      "Epoch 42/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 87.3427 - ortho_2_loss: 67.1521 - tf.math.reduce_sum_13_loss: 2.0798 - tf.math.multiply_27_loss: 18.1108\n",
      "Epoch 43/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 87.3011 - ortho_2_loss: 67.3146 - tf.math.reduce_sum_13_loss: 2.1259 - tf.math.multiply_27_loss: 17.8606\n",
      "Epoch 44/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 86.3510 - ortho_2_loss: 66.7324 - tf.math.reduce_sum_13_loss: 2.1722 - tf.math.multiply_27_loss: 17.4464\n",
      "Epoch 45/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 85.9740 - ortho_2_loss: 66.5758 - tf.math.reduce_sum_13_loss: 2.2085 - tf.math.multiply_27_loss: 17.1897\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 1s 15ms/step - loss: 85.8619 - ortho_2_loss: 66.7775 - tf.math.reduce_sum_13_loss: 2.2368 - tf.math.multiply_27_loss: 16.8477\n",
      "Epoch 47/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 85.0585 - ortho_2_loss: 66.2185 - tf.math.reduce_sum_13_loss: 2.2709 - tf.math.multiply_27_loss: 16.5691\n",
      "Epoch 48/50\n",
      "98/98 [==============================] - 2s 15ms/step - loss: 84.6498 - ortho_2_loss: 66.0396 - tf.math.reduce_sum_13_loss: 2.3025 - tf.math.multiply_27_loss: 16.3077\n",
      "Epoch 49/50\n",
      "98/98 [==============================] - 2s 16ms/step - loss: 84.6285 - ortho_2_loss: 66.2949 - tf.math.reduce_sum_13_loss: 2.3255 - tf.math.multiply_27_loss: 16.0081\n",
      "Epoch 50/50\n",
      "98/98 [==============================] - 1s 15ms/step - loss: 83.8235 - ortho_2_loss: 65.6970 - tf.math.reduce_sum_13_loss: 2.3486 - tf.math.multiply_27_loss: 15.7779\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2ccf305e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2ccf305e0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2ccf30670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2ccf30670> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2ccf30700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2ccf30700> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:10:08.664012: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 4s 32ms/step - loss: 0.0687 - ortho_2_loss: 0.0687 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 2/15\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 0.0672 - ortho_2_loss: 0.0672 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 3/15\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 0.0658 - ortho_2_loss: 0.0658 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 4/15\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 0.0646 - ortho_2_loss: 0.0646 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 5/15\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 0.0632 - ortho_2_loss: 0.0632 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 6/15\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 0.0620 - ortho_2_loss: 0.0620 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 7/15\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 0.0612 - ortho_2_loss: 0.0612 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 8/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0598 - ortho_2_loss: 0.0598 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 9/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0588 - ortho_2_loss: 0.0588 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 10/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0584 - ortho_2_loss: 0.0584 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 11/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0571 - ortho_2_loss: 0.0571 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 12/15\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 0.0563 - ortho_2_loss: 0.0563 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 13/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0561 - ortho_2_loss: 0.0561 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 14/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0549 - ortho_2_loss: 0.0549 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 15/15\n",
      "98/98 [==============================] - 2s 22ms/step - loss: 0.0542 - ortho_2_loss: 0.0542 - tf.math.reduce_sum_14_loss: 0.0000e+00 - tf.math.multiply_29_loss: 0.0000e+00\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2ccf32a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x2ccf32a70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2ccf32b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x2ccf32b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2ccf32b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x2ccf32b90> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:10:44.763946: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 4s 31ms/step - loss: 617.1133 - ortho_2_loss: 69.3360 - tf.math.reduce_sum_15_loss: 14.7288 - tf.math.multiply_31_loss: 533.0487\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 3s 28ms/step - loss: 367.5789 - ortho_2_loss: 69.3723 - tf.math.reduce_sum_15_loss: 1.5063 - tf.math.multiply_31_loss: 296.7002\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 3s 26ms/step - loss: 282.9397 - ortho_2_loss: 69.4234 - tf.math.reduce_sum_15_loss: 1.1289 - tf.math.multiply_31_loss: 212.3874\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 3s 26ms/step - loss: 238.3148 - ortho_2_loss: 69.4834 - tf.math.reduce_sum_15_loss: 0.6730 - tf.math.multiply_31_loss: 168.1585\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 209.0697 - ortho_2_loss: 69.5568 - tf.math.reduce_sum_15_loss: 0.5233 - tf.math.multiply_31_loss: 138.9895\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 186.1237 - ortho_2_loss: 69.6518 - tf.math.reduce_sum_15_loss: 0.2638 - tf.math.multiply_31_loss: 116.2081\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 169.8141 - ortho_2_loss: 69.7595 - tf.math.reduce_sum_15_loss: 0.1942 - tf.math.multiply_31_loss: 99.8604\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 156.9545 - ortho_2_loss: 69.8832 - tf.math.reduce_sum_15_loss: 0.1383 - tf.math.multiply_31_loss: 86.9329\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 147.3440 - ortho_2_loss: 70.0111 - tf.math.reduce_sum_15_loss: 0.1273 - tf.math.multiply_31_loss: 77.2056\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 139.4531 - ortho_2_loss: 70.1517 - tf.math.reduce_sum_15_loss: 0.1131 - tf.math.multiply_31_loss: 69.1882\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 133.4199 - ortho_2_loss: 70.2861 - tf.math.reduce_sum_15_loss: 0.1093 - tf.math.multiply_31_loss: 63.0245\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 128.3271 - ortho_2_loss: 70.4240 - tf.math.reduce_sum_15_loss: 0.1170 - tf.math.multiply_31_loss: 57.7860\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 2s 25ms/step - loss: 124.0105 - ortho_2_loss: 70.5689 - tf.math.reduce_sum_15_loss: 0.1265 - tf.math.multiply_31_loss: 53.3151\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 120.2213 - ortho_2_loss: 70.6845 - tf.math.reduce_sum_15_loss: 0.1452 - tf.math.multiply_31_loss: 49.3916\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 117.1984 - ortho_2_loss: 70.7895 - tf.math.reduce_sum_15_loss: 0.1715 - tf.math.multiply_31_loss: 46.2374\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 114.4819 - ortho_2_loss: 70.9124 - tf.math.reduce_sum_15_loss: 0.2058 - tf.math.multiply_31_loss: 43.3637\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 112.0845 - ortho_2_loss: 70.9478 - tf.math.reduce_sum_15_loss: 0.2492 - tf.math.multiply_31_loss: 40.8874\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 110.0501 - ortho_2_loss: 70.9930 - tf.math.reduce_sum_15_loss: 0.2969 - tf.math.multiply_31_loss: 38.7602\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 108.1294 - ortho_2_loss: 71.0645 - tf.math.reduce_sum_15_loss: 0.3519 - tf.math.multiply_31_loss: 36.7130\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 106.3885 - ortho_2_loss: 71.0247 - tf.math.reduce_sum_15_loss: 0.4121 - tf.math.multiply_31_loss: 34.9518\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 104.9207 - ortho_2_loss: 70.9884 - tf.math.reduce_sum_15_loss: 0.4793 - tf.math.multiply_31_loss: 33.4530\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 103.5329 - ortho_2_loss: 71.0294 - tf.math.reduce_sum_15_loss: 0.5471 - tf.math.multiply_31_loss: 31.9564\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 102.2833 - ortho_2_loss: 70.8884 - tf.math.reduce_sum_15_loss: 0.6211 - tf.math.multiply_31_loss: 30.7739\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 101.1417 - ortho_2_loss: 70.8033 - tf.math.reduce_sum_15_loss: 0.6885 - tf.math.multiply_31_loss: 29.6499\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 100.2469 - ortho_2_loss: 70.8267 - tf.math.reduce_sum_15_loss: 0.7565 - tf.math.multiply_31_loss: 28.6637\n",
      "Epoch 26/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 99.1958 - ortho_2_loss: 70.5863 - tf.math.reduce_sum_15_loss: 0.8269 - tf.math.multiply_31_loss: 27.7826\n",
      "Epoch 27/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 98.3838 - ortho_2_loss: 70.5264 - tf.math.reduce_sum_15_loss: 0.8963 - tf.math.multiply_31_loss: 26.9612\n",
      "Epoch 28/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 97.7508 - ortho_2_loss: 70.5136 - tf.math.reduce_sum_15_loss: 0.9649 - tf.math.multiply_31_loss: 26.2722\n",
      "Epoch 29/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 96.8226 - ortho_2_loss: 70.2291 - tf.math.reduce_sum_15_loss: 1.0380 - tf.math.multiply_31_loss: 25.5555\n",
      "Epoch 30/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 96.1622 - ortho_2_loss: 70.0917 - tf.math.reduce_sum_15_loss: 1.1006 - tf.math.multiply_31_loss: 24.9700\n",
      "Epoch 31/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 95.6969 - ortho_2_loss: 70.1197 - tf.math.reduce_sum_15_loss: 1.1700 - tf.math.multiply_31_loss: 24.4072\n",
      "Epoch 32/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 94.8619 - ortho_2_loss: 69.7803 - tf.math.reduce_sum_15_loss: 1.2397 - tf.math.multiply_31_loss: 23.8419\n",
      "Epoch 33/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 94.2124 - ortho_2_loss: 69.6117 - tf.math.reduce_sum_15_loss: 1.3099 - tf.math.multiply_31_loss: 23.2908\n",
      "Epoch 34/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 93.8894 - ortho_2_loss: 69.6439 - tf.math.reduce_sum_15_loss: 1.3734 - tf.math.multiply_31_loss: 22.8721\n",
      "Epoch 35/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 93.0542 - ortho_2_loss: 69.2745 - tf.math.reduce_sum_15_loss: 1.4376 - tf.math.multiply_31_loss: 22.3420\n",
      "Epoch 36/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 92.5247 - ortho_2_loss: 69.0837 - tf.math.reduce_sum_15_loss: 1.5057 - tf.math.multiply_31_loss: 21.9352\n",
      "Epoch 37/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 92.1700 - ortho_2_loss: 69.1291 - tf.math.reduce_sum_15_loss: 1.5740 - tf.math.multiply_31_loss: 21.4669\n",
      "Epoch 38/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 91.4390 - ortho_2_loss: 68.7212 - tf.math.reduce_sum_15_loss: 1.6340 - tf.math.multiply_31_loss: 21.0838\n",
      "Epoch 39/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 90.9212 - ortho_2_loss: 68.5160 - tf.math.reduce_sum_15_loss: 1.6961 - tf.math.multiply_31_loss: 20.7091\n",
      "Epoch 40/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 90.5932 - ortho_2_loss: 68.5888 - tf.math.reduce_sum_15_loss: 1.7535 - tf.math.multiply_31_loss: 20.2509\n",
      "Epoch 41/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 89.8143 - ortho_2_loss: 68.1172 - tf.math.reduce_sum_15_loss: 1.8147 - tf.math.multiply_31_loss: 19.8824\n",
      "Epoch 42/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 89.3889 - ortho_2_loss: 67.9404 - tf.math.reduce_sum_15_loss: 1.8674 - tf.math.multiply_31_loss: 19.5812\n",
      "Epoch 43/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 89.1551 - ortho_2_loss: 68.0503 - tf.math.reduce_sum_15_loss: 1.9217 - tf.math.multiply_31_loss: 19.1831\n",
      "Epoch 44/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 88.3316 - ortho_2_loss: 67.5339 - tf.math.reduce_sum_15_loss: 1.9761 - tf.math.multiply_31_loss: 18.8216\n",
      "Epoch 45/50\n",
      "98/98 [==============================] - 2s 24ms/step - loss: 87.9943 - ortho_2_loss: 67.3798 - tf.math.reduce_sum_15_loss: 2.0122 - tf.math.multiply_31_loss: 18.6024\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 2s 23ms/step - loss: 87.7544 - ortho_2_loss: 67.4823 - tf.math.reduce_sum_15_loss: 2.0692 - tf.math.multiply_31_loss: 18.2029\n",
      "Epoch 47/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 86.9603 - ortho_2_loss: 66.9823 - tf.math.reduce_sum_15_loss: 2.1102 - tf.math.multiply_31_loss: 17.8678\n",
      "Epoch 48/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 86.5204 - ortho_2_loss: 66.7582 - tf.math.reduce_sum_15_loss: 2.1531 - tf.math.multiply_31_loss: 17.6092\n",
      "Epoch 49/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 86.4774 - ortho_2_loss: 66.9895 - tf.math.reduce_sum_15_loss: 2.1888 - tf.math.multiply_31_loss: 17.2991\n",
      "Epoch 50/50\n",
      "98/98 [==============================] - 2s 23ms/step - loss: 85.6261 - ortho_2_loss: 66.3986 - tf.math.reduce_sum_15_loss: 2.2272 - tf.math.multiply_31_loss: 17.0003\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x5c55b4f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x5c55b4f70> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x5c55b5000> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x5c55b5000> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x5c55b5090> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x5c55b5090> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:14:01.573158: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 14s 135ms/step - loss: 0.0689 - ortho_2_loss: 0.0689 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 2/15\n",
      "98/98 [==============================] - 12s 127ms/step - loss: 0.0678 - ortho_2_loss: 0.0678 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 3/15\n",
      "98/98 [==============================] - 12s 125ms/step - loss: 0.0666 - ortho_2_loss: 0.0666 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 4/15\n",
      "98/98 [==============================] - 12s 125ms/step - loss: 0.0656 - ortho_2_loss: 0.0656 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 5/15\n",
      "98/98 [==============================] - 12s 123ms/step - loss: 0.0644 - ortho_2_loss: 0.0644 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 6/15\n",
      "98/98 [==============================] - 12s 122ms/step - loss: 0.0633 - ortho_2_loss: 0.0633 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 7/15\n",
      "98/98 [==============================] - 12s 122ms/step - loss: 0.0625 - ortho_2_loss: 0.0625 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 8/15\n",
      "98/98 [==============================] - 12s 122ms/step - loss: 0.0613 - ortho_2_loss: 0.0613 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 9/15\n",
      "98/98 [==============================] - 12s 122ms/step - loss: 0.0604 - ortho_2_loss: 0.0604 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 10/15\n",
      "98/98 [==============================] - 12s 125ms/step - loss: 0.0599 - ortho_2_loss: 0.0599 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 11/15\n",
      "98/98 [==============================] - 12s 127ms/step - loss: 0.0587 - ortho_2_loss: 0.0587 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 12/15\n",
      "98/98 [==============================] - 12s 124ms/step - loss: 0.0580 - ortho_2_loss: 0.0580 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 13/15\n",
      "98/98 [==============================] - 12s 126ms/step - loss: 0.0577 - ortho_2_loss: 0.0577 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 14/15\n",
      "98/98 [==============================] - 12s 127ms/step - loss: 0.0566 - ortho_2_loss: 0.0566 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n",
      "Epoch 15/15\n",
      "98/98 [==============================] - 12s 126ms/step - loss: 0.0559 - ortho_2_loss: 0.0559 - tf.math.reduce_sum_16_loss: 0.0000e+00 - tf.math.multiply_33_loss: 0.0000e+00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zohairshafi/miniforge3/lib/python3.10/site-packages/sklearn/decomposition/_nmf.py:1692: ConvergenceWarning: Maximum number of iterations 4000 reached. Increase it to improve convergence.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "WARNING:tensorflow:AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x4dc596680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function main_loss.<locals>.line_loss at 0x4dc596680> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('alpha',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x4dc596710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_ortho_line.<locals>.loss_3rd at 0x4dc596710> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('gamma',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING:tensorflow:AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x4dc5967a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function l_sparse_line.<locals>.loss_4th at 0x4dc5967a0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: closure mismatch, requested ('delta',), but source function had ()\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-11 15:17:12.387717: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98/98 [==============================] - 16s 156ms/step - loss: 584.9823 - ortho_2_loss: 69.3379 - tf.math.reduce_sum_17_loss: 3.0719 - tf.math.multiply_35_loss: 512.5725\n",
      "Epoch 2/50\n",
      "98/98 [==============================] - 14s 148ms/step - loss: 361.7868 - ortho_2_loss: 69.3762 - tf.math.reduce_sum_17_loss: 0.7314 - tf.math.multiply_35_loss: 291.6791\n",
      "Epoch 3/50\n",
      "98/98 [==============================] - 14s 143ms/step - loss: 281.6887 - ortho_2_loss: 69.4281 - tf.math.reduce_sum_17_loss: 0.6219 - tf.math.multiply_35_loss: 211.6386\n",
      "Epoch 4/50\n",
      "98/98 [==============================] - 14s 139ms/step - loss: 235.6213 - ortho_2_loss: 69.4953 - tf.math.reduce_sum_17_loss: 0.3366 - tf.math.multiply_35_loss: 165.7894\n",
      "Epoch 5/50\n",
      "98/98 [==============================] - 14s 138ms/step - loss: 205.7632 - ortho_2_loss: 69.5782 - tf.math.reduce_sum_17_loss: 0.2014 - tf.math.multiply_35_loss: 135.9835\n",
      "Epoch 6/50\n",
      "98/98 [==============================] - 13s 134ms/step - loss: 185.0595 - ortho_2_loss: 69.6709 - tf.math.reduce_sum_17_loss: 0.1339 - tf.math.multiply_35_loss: 115.2546\n",
      "Epoch 7/50\n",
      "98/98 [==============================] - 14s 138ms/step - loss: 168.9425 - ortho_2_loss: 69.7846 - tf.math.reduce_sum_17_loss: 0.0819 - tf.math.multiply_35_loss: 99.0759\n",
      "Epoch 8/50\n",
      "98/98 [==============================] - 13s 135ms/step - loss: 157.0775 - ortho_2_loss: 69.9055 - tf.math.reduce_sum_17_loss: 0.0674 - tf.math.multiply_35_loss: 87.1046\n",
      "Epoch 9/50\n",
      "98/98 [==============================] - 14s 140ms/step - loss: 147.4852 - ortho_2_loss: 70.0370 - tf.math.reduce_sum_17_loss: 0.0515 - tf.math.multiply_35_loss: 77.3967\n",
      "Epoch 10/50\n",
      "98/98 [==============================] - 13s 136ms/step - loss: 139.8433 - ortho_2_loss: 70.1840 - tf.math.reduce_sum_17_loss: 0.0530 - tf.math.multiply_35_loss: 69.6064\n",
      "Epoch 11/50\n",
      "98/98 [==============================] - 14s 141ms/step - loss: 133.6877 - ortho_2_loss: 70.3184 - tf.math.reduce_sum_17_loss: 0.0649 - tf.math.multiply_35_loss: 63.3045\n",
      "Epoch 12/50\n",
      "98/98 [==============================] - 14s 142ms/step - loss: 128.6392 - ortho_2_loss: 70.4556 - tf.math.reduce_sum_17_loss: 0.0762 - tf.math.multiply_35_loss: 58.1074\n",
      "Epoch 13/50\n",
      "98/98 [==============================] - 14s 143ms/step - loss: 124.3753 - ortho_2_loss: 70.6010 - tf.math.reduce_sum_17_loss: 0.0962 - tf.math.multiply_35_loss: 53.6781\n",
      "Epoch 14/50\n",
      "98/98 [==============================] - 14s 138ms/step - loss: 120.8740 - ortho_2_loss: 70.7061 - tf.math.reduce_sum_17_loss: 0.1213 - tf.math.multiply_35_loss: 50.0465\n",
      "Epoch 15/50\n",
      "98/98 [==============================] - 14s 138ms/step - loss: 117.8548 - ortho_2_loss: 70.8055 - tf.math.reduce_sum_17_loss: 0.1524 - tf.math.multiply_35_loss: 46.8969\n",
      "Epoch 16/50\n",
      "98/98 [==============================] - 13s 136ms/step - loss: 115.4529 - ortho_2_loss: 70.9102 - tf.math.reduce_sum_17_loss: 0.1866 - tf.math.multiply_35_loss: 44.3561\n",
      "Epoch 17/50\n",
      "98/98 [==============================] - 13s 137ms/step - loss: 113.4314 - ortho_2_loss: 70.9368 - tf.math.reduce_sum_17_loss: 0.2248 - tf.math.multiply_35_loss: 42.2698\n",
      "Epoch 18/50\n",
      "98/98 [==============================] - 14s 139ms/step - loss: 111.6115 - ortho_2_loss: 70.9691 - tf.math.reduce_sum_17_loss: 0.2648 - tf.math.multiply_35_loss: 40.3776\n",
      "Epoch 19/50\n",
      "98/98 [==============================] - 13s 136ms/step - loss: 110.3054 - ortho_2_loss: 71.0453 - tf.math.reduce_sum_17_loss: 0.3054 - tf.math.multiply_35_loss: 38.9547\n",
      "Epoch 20/50\n",
      "98/98 [==============================] - 13s 135ms/step - loss: 108.8628 - ortho_2_loss: 71.0090 - tf.math.reduce_sum_17_loss: 0.3486 - tf.math.multiply_35_loss: 37.5051\n",
      "Epoch 21/50\n",
      "98/98 [==============================] - 14s 139ms/step - loss: 107.6434 - ortho_2_loss: 71.0030 - tf.math.reduce_sum_17_loss: 0.3940 - tf.math.multiply_35_loss: 36.2464\n",
      "Epoch 22/50\n",
      "98/98 [==============================] - 13s 137ms/step - loss: 106.6733 - ortho_2_loss: 71.0539 - tf.math.reduce_sum_17_loss: 0.4396 - tf.math.multiply_35_loss: 35.1798\n",
      "Epoch 23/50\n",
      "98/98 [==============================] - 13s 135ms/step - loss: 105.4607 - ortho_2_loss: 70.9718 - tf.math.reduce_sum_17_loss: 0.4877 - tf.math.multiply_35_loss: 34.0013\n",
      "Epoch 24/50\n",
      "98/98 [==============================] - 13s 136ms/step - loss: 104.5443 - ortho_2_loss: 70.9428 - tf.math.reduce_sum_17_loss: 0.5356 - tf.math.multiply_35_loss: 33.0658\n",
      "Epoch 25/50\n",
      "98/98 [==============================] - 14s 139ms/step - loss: 103.8115 - ortho_2_loss: 70.9877 - tf.math.reduce_sum_17_loss: 0.5801 - tf.math.multiply_35_loss: 32.2438\n",
      "Epoch 26/50\n",
      "28/98 [=======>......................] - ETA: 10s - loss: 102.9754 - ortho_2_loss: 70.7139 - tf.math.reduce_sum_17_loss: 0.6125 - tf.math.multiply_35_loss: 31.6490"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                     | 0/1 [17:22<?, ?it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "filename = './data/email.pkl'\n",
    "run_count = 1\n",
    "hyp_key = 'hyp_email'\n",
    "outfile = './email_line.pkl'\n",
    "\n",
    "# ap = argparse.ArgumentParser()\n",
    "# ap.add_argument(\"-g\", \"--graph_path\", required = True, help = 'Path to an nx.Graph object stored as a .pkl file')\n",
    "# ap.add_argument(\"-r\", \"--run_count\", required = True, help = \"Number of iterations for the experiment\", default = 1)\n",
    "# ap.add_argument(\"-k\", \"--hyp_key\", required = True, help = \"Key to index the hyperparameter json file\")\n",
    "# ap.add_argument(\"-o\", \"--outfile\", required = True, help = \"File name to save results into\")\n",
    "\n",
    "# args = vars(ap.parse_args())\n",
    "\n",
    "# filename = args['graph_path']\n",
    "# run_count = args['run_count']\n",
    "# hyp_key = args['hyp_key']\n",
    "# outfile = args['outfile']\n",
    "\n",
    "#################################\n",
    "######### Read In Graph #########\n",
    "#################################\n",
    "with open(filename, 'rb') as file: \n",
    "    graph_dict = pkl.load(file)\n",
    "    \n",
    "graph = nx.Graph(nx.to_numpy_array(graph_dict['graph']))    \n",
    "graph = nx.Graph(nx.to_numpy_array(graph))\n",
    "\n",
    "\n",
    "#################################\n",
    "#### Generate Sense Features ####\n",
    "#################################\n",
    "sense_feat_dict, sense_features = get_sense_features(graph, ppr_flag = 'std')\n",
    "\n",
    "uncorrelated_feats = ['Degree',\n",
    "                    'Clustering Coefficient',\n",
    "                    'Personalized Page Rank - Standard Deviation',\n",
    "                    'Average Neighbor Degree',\n",
    "                    'Average Neighbor Clustering',\n",
    "                    'Eccentricity',\n",
    "                    'Katz Centrality']\n",
    "sense_features = sense_features[:, [list(sense_feat_dict).index(feat) for feat in uncorrelated_feats]]\n",
    "sense_feat_dict = {feat : idx for idx, feat in enumerate(uncorrelated_feats)}\n",
    "\n",
    "#################################\n",
    "######## Hyperparameters ########\n",
    "#################################\n",
    "\n",
    "# Define static ones to override or read in from a file\n",
    "\n",
    "if hyp_key == '':\n",
    "    hyp = {'line' : {'alpha' : 0.1, \n",
    "                     'ortho' : 0, \n",
    "                     'sparse' : 0, \n",
    "                     'epochs' : 15, \n",
    "                     'batch_size' : 1024, \n",
    "                     'lr' : 1e-3}, \n",
    "\n",
    "          'line+xm' : {'alpha' : 100, \n",
    "                      'ortho' : 10, \n",
    "                      'sparse' : 10, \n",
    "                      'epochs' : 50, \n",
    "                      'batch_size' : 1024, \n",
    "                      'lr' : 5e-4}}\n",
    "else: \n",
    "    with open('scripts/hyp.json', 'r') as file: \n",
    "        hyp_file = json.load(file)\n",
    "        hyp = hyp_file[hyp_key]\n",
    "\n",
    "\n",
    "#################################\n",
    "######## Run Experiment #########\n",
    "#################################\n",
    "\n",
    "dimensions = [16, 32, 64, 256, 512]\n",
    "results = {d : {} for d in dimensions}\n",
    "run_time = []\n",
    "\n",
    "for run_idx in tqdm(range(run_count)):\n",
    "    \n",
    "    run_start = time.time()\n",
    "\n",
    "    for d in dimensions: \n",
    "    \n",
    "        # Embed \n",
    "        \n",
    "        # Standard LINE\n",
    "        line_start = time.time()\n",
    "        line = LINE(graph, \n",
    "                embedding_size = d,\n",
    "                sense_features = sense_features,\n",
    "                alpha = hyp['line']['alpha'], \n",
    "                ortho = hyp['line']['ortho'], \n",
    "                sparse = hyp['line']['sparse'],\n",
    "                learning_rate =  hyp['line']['lr'],\n",
    "                order = 'second', \n",
    "                batch_size = hyp['line']['batch_size'])\n",
    "\n",
    "        history = line.train(epochs = hyp['line']['epochs'])\n",
    "\n",
    "        e = line.get_embeddings()\n",
    "        embed_og = np.array([e[node_name] for node_name in graph.nodes()])\n",
    "        embed_og = (embed_og - np.min(embed_og)) / np.ptp(embed_og)\n",
    "        line_time = (time.time() - line_start) / hyp['line']['epochs']\n",
    "\n",
    "\n",
    "        feature_dict_og = find_feature_membership(input_embed = embed_og,\n",
    "                                                            embed_name = 'LINE',\n",
    "                                                            sense_features = sense_features,\n",
    "                                                            sense_feat_dict = sense_feat_dict,\n",
    "                                                            top_k = 8,\n",
    "                                                            solver = 'nmf')\n",
    "\n",
    "        explain_og = feature_dict_og['explain_norm']\n",
    "        error_og = sense_features * np.log((sense_features + 1e-10) / ((embed_og @ feature_dict_og['explain_norm']) + 1e-10)) - sense_features + (embed_og @ feature_dict_og['explain_norm'])\n",
    "        explain_og = (explain_og - np.min(explain_og)) / np.ptp(explain_og)\n",
    "        \n",
    "        # LINE+XM\n",
    "        line_plus_start = time.time()\n",
    "        line_plus = LINE(graph, \n",
    "                        embedding_size = d,\n",
    "                        sense_features = sense_features,\n",
    "                        alpha = hyp['line+xm']['alpha'], \n",
    "                        ortho = hyp['line+xm']['ortho'], \n",
    "                        sparse = hyp['line+xm']['sparse'],\n",
    "                        learning_rate =  hyp['line+xm']['lr'],\n",
    "                        order = 'second', \n",
    "                        batch_size = hyp['line+xm']['batch_size'])\n",
    "\n",
    "        history = line_plus.train(epochs = hyp['line+xm']['epochs'])\n",
    "\n",
    "        e = line_plus.get_embeddings()\n",
    "        embed_plus = np.array([e[node_name] for node_name in graph.nodes()])\n",
    "        embed_plus = (embed_plus - np.min(embed_plus)) / np.ptp(embed_plus)\n",
    "        line_plus_time = (time.time() - line_plus_start) / hyp['line+xm']['epochs']\n",
    "\n",
    "        feature_dict_plus = find_feature_membership(input_embed = embed_plus,\n",
    "                                                            embed_name = 'LINE+XM',\n",
    "                                                            sense_features = sense_features,\n",
    "                                                            sense_feat_dict = sense_feat_dict,\n",
    "                                                            top_k = 8,\n",
    "                                                            solver = 'nmf')\n",
    "\n",
    "        explain_plus = feature_dict_plus['explain_norm']\n",
    "        error_plus = sense_features * np.log((sense_features + 1e-10) / ((embed_plus @ feature_dict_plus['explain_norm']) + 1e-10)) - sense_features + (embed_plus @ feature_dict_plus['explain_norm'])\n",
    "        explain_plus = (explain_plus - np.min(explain_plus)) / np.ptp(explain_plus)\n",
    "\n",
    "        # Generate Node Explanations\n",
    "        Y_og = embed_og\n",
    "        sense_mat = tf.einsum('ij, ik -> ijk', Y_og, sense_features)\n",
    "        Y_og_norm = tf.linalg.diag_part(tf.matmul(Y_og, Y_og, transpose_b = True), k = 0)\n",
    "        sense_norm = tf.linalg.diag_part(tf.matmul(sense_features, sense_features, transpose_b = True), k = 0)\n",
    "        norm = Y_og_norm * tf.cast(sense_norm, tf.float32)\n",
    "        D_og = tf.transpose(tf.transpose(sense_mat) / norm)\n",
    "\n",
    "\n",
    "        Y_plus = embed_plus\n",
    "        sense_mat = tf.einsum('ij, ik -> ijk', Y_plus, sense_features)\n",
    "        Y_plus_norm = tf.linalg.diag_part(tf.matmul(Y_plus, Y_plus, transpose_b = True), k = 0)\n",
    "        sense_norm = tf.linalg.diag_part(tf.matmul(sense_features, sense_features, transpose_b = True), k = 0)\n",
    "        norm = Y_plus_norm * tf.cast(sense_norm, tf.float32)\n",
    "        D_plus = tf.transpose(tf.transpose(sense_mat) / norm)\n",
    "\n",
    "        norm_og = [np.linalg.norm(D_og[node, :, :], ord = 'nuc') for node in range(len(graph))]\n",
    "        norm_plus = [np.linalg.norm(D_plus[node, :, :], ord = 'nuc') for node in range(len(graph))]\n",
    "        \n",
    "        try:\n",
    "            results[d]['norm_og'].append(norm_og)\n",
    "            results[d]['norm_plus'].append(norm_plus)\n",
    "            results[d]['explain_og_norm'].append(explain_og_norm)\n",
    "            results[d]['explain_plus_norm'].append(explain_plus_norm)\n",
    "            results[d]['line_time'].append(line_time)\n",
    "            results[d]['line+xm_time'].append(line_plus_time)\n",
    "            results[d]['error_og'].append(error_og)\n",
    "            results[d]['error_plus'].append(error_plus)\n",
    "            \n",
    "        except: \n",
    "            results[d]['norm_og'] = [norm_og]\n",
    "            results[d]['norm_plus'] = [norm_plus]\n",
    "            results[d]['explain_og_norm'] = [explain_og_norm]\n",
    "            results[d]['explain_plus_norm'] = [explain_plus_norm]\n",
    "            results[d]['line_time'] = [line_time]\n",
    "            results[d]['line+xm_time'] = [line_plus_time]\n",
    "            results[d]['error_og'] = [error_og]\n",
    "            results[d]['error_plus'] = [error_plus]\n",
    "            \n",
    "        results[d]['embed_og'] = embed_og\n",
    "        results[d]['embed_plus'] = embed_plus\n",
    "    \n",
    "    with open(outfile, 'wb') as file: \n",
    "        pkl.dump(results, file)\n",
    "        \n",
    "    with open(outfile, 'wb') as file: \n",
    "        pkl.dump(results, file)\n",
    "\n",
    "    run_time.append(time.time() - run_start)\n",
    "\n",
    "    with open(outfile + '_progress.txt', 'w') as file: \n",
    "        string = 'Current Run : ' + str(run_idx)\n",
    "        string += '\\nLast Iteration Time : ' + str(run_time[-1]) + 's'\n",
    "        string += '\\nAverage Iteration Time : ' + str(np.mean(run_time)) + 's'\n",
    "        string += '\\nEstimated Time Left : ' + str(np.mean(run_time) * (run_count - run_idx)) + 's'\n",
    "        file.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2861260f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74a46d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
