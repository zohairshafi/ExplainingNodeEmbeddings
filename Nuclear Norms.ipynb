{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9197b434",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f06dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run utils.ipynb\n",
    "%run SDNE+.ipynb\n",
    "%run LINE+.ipynb\n",
    "%run Hyperparameters.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d1dd03",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### SDNE vs SDNE+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e98837",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('./email.pkl', 'rb') as file: \n",
    "    graph_dict = pkl.load(file)\n",
    "    \n",
    "graph = nx.Graph(nx.to_numpy_array(graph_dict['graph']))    \n",
    "graph = nx.Graph(nx.to_numpy_array(graph_dict))\n",
    "\n",
    "\n",
    "sense_feat_dict, sense_features = get_sense_features(graph, ppr_flag = 'std')\n",
    "\n",
    "\n",
    "\n",
    "nuc_list = []\n",
    "error_list = []\n",
    "\n",
    "hyp = sdne_email_hyp\n",
    "\n",
    "for run_idx in tqdm(range(40)):\n",
    "\n",
    "    models = {x : {} for x in hyp}\n",
    "    models_p_init = {x : {} for x in hyp}\n",
    "    \n",
    "\n",
    "    for d in hyp:\n",
    "        \n",
    "        sdne = SDNE_plus(graph, \n",
    "                  hidden_size = [32, d], \n",
    "                  lr = hyp[d]['sdne']['lr'],\n",
    "                  sense_features = sense_features.astype(np.float32),\n",
    "                  alpha = hyp[d]['sdne']['alpha'], \n",
    "                  beta = hyp[d]['sdne']['beta'], \n",
    "                  gamma = hyp[d]['sdne']['gamma'], \n",
    "                  delta = hyp[d]['sdne']['delta'])\n",
    "        history = sdne.train(epochs = 200, batch_size = 1024)\n",
    "        e = sdne.get_embeddings()\n",
    "        embed_og = np.array([e[node_name] for node_name in graph.nodes()])\n",
    "        embed_og = (embed_og - np.min(embed_og)) / np.ptp(embed_og)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        feature_dict_og = find_feature_membership(input_embed = embed_og,\n",
    "                                                            embed_name = 'SDNE',\n",
    "                                                            sense_features = sense_features,\n",
    "                                                            sense_feat_dict = sense_feat_dict,\n",
    "                                                            top_k = 8,\n",
    "                                                            solver = 'nmf')\n",
    "\n",
    "        explain_og = feature_dict_og['explain_norm']\n",
    "        error_og = sense_features * np.log((sense_features + 1e-10) / ((embed_og @ feature_dict_og['explain_norm']) + 1e-10)) - sense_features + (embed_og @ feature_dict_og['explain_norm'])\n",
    "        \n",
    "        explain_og = (explain_og - np.min(explain_og)) / np.ptp(explain_og)\n",
    "        \n",
    "        \n",
    "        \n",
    "        models[d]['e_norm_nuc'] = np.linalg.norm(explain_og, ord = 'nuc')\n",
    "        models[d]['e_norm_l1'] = np.linalg.norm(explain_og, ord = 1)\n",
    "        models[d]['e_norm_l2'] = np.linalg.norm(explain_og, ord = 2)\n",
    "        models[d]['entropy'] = np.std(explain_og, axis = 1)\n",
    "        models[d]['error'] = np.sum(error_og)\n",
    "        \n",
    "        \n",
    "        sdne_plus_init = SDNE_plus(graph, \n",
    "                          hidden_size = [32, d], \n",
    "                          lr = hyp[d]['sdne+ init']['lr'],\n",
    "                          sense_features = sense_features.astype(np.float32),\n",
    "                          alpha = hyp[d]['sdne+ init']['alpha'], \n",
    "                          beta = hyp[d]['sdne+ init']['beta'], \n",
    "                          gamma = hyp[d]['sdne+ init']['gamma'], \n",
    "                          delta = hyp[d]['sdne+ init']['delta'])\n",
    "\n",
    "        sdne_plus_init.model.set_weights(sdne.model.get_weights())\n",
    "        history = sdne_plus_init.train(epochs = hyp[d]['sdne+ init']['epochs'], batch_size = 1024)\n",
    "        e = sdne_plus_init.get_embeddings()\n",
    "        embed_plus_init = np.array([e[node_name] for node_name in graph.nodes()])\n",
    "        embed_plus_init = (embed_plus_init - np.min(embed_plus_init)) / np.ptp(embed_plus_init)\n",
    "        \n",
    "\n",
    "        feature_dict_plus_init = find_feature_membership(input_embed = embed_plus_init,\n",
    "                                                            embed_name = 'SDNE+ Init',\n",
    "                                                            sense_features = sense_features,\n",
    "                                                            sense_feat_dict = sense_feat_dict,\n",
    "                                                            top_k = 8,\n",
    "                                                            solver = 'nmf')\n",
    "\n",
    "        explain_plus_init = feature_dict_plus_init['explain_norm']\n",
    "        error_plus_init = sense_features * np.log((sense_features + 1e-10) / ((embed_plus_init @ feature_dict_plus_init['explain_norm']) + 1e-10)) - sense_features + (embed_plus_init @ feature_dict_plus_init['explain_norm'])\n",
    "        \n",
    "        explain_plus_init = (explain_plus_init - np.min(explain_plus_init)) / np.ptp(explain_plus_init)\n",
    "        \n",
    "        models_p_init[d]['e_norm_nuc'] = np.linalg.norm(explain_plus_init, ord = 'nuc')\n",
    "        models_p_init[d]['e_norm_l1'] = np.linalg.norm(explain_plus_init, ord = 1)\n",
    "        models_p_init[d]['e_norm_l2'] = np.linalg.norm(explain_plus_init, ord = 2)\n",
    "        models_p_init[d]['entropy'] = np.std(explain_plus_init, axis = 1)\n",
    "        models_p_init[d]['error'] = np.sum(error_plus_init)\n",
    "        \n",
    "        del sdne\n",
    "        del sdne_plus_init\n",
    "        \n",
    "    nuc_norm = np.array([[models[d]['e_norm_nuc'] for d in hyp], \n",
    "                        [models_p_init[d]['e_norm_nuc'] for d in hyp],]) \n",
    "    error = np.array([[models[d]['error'] for d in hyp], \n",
    "                        [models_p_init[d]['error'] for d in hyp],]) \n",
    "    \n",
    "    \n",
    "    nuc_list.append(nuc_norm)\n",
    "    error_list.append(error)\n",
    "\n",
    "    with open('./email_runs_40_sdne.pkl', 'wb') as file:\n",
    "        pkl.dump([nuc_list, error_list], file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e802f3",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nuc_mean = np.mean(np.array(nuc_list), axis = 0)\n",
    "nuc_std = np.std(np.array(nuc_list), axis = 0) / np.sqrt(np.array(nuc_list).shape[0])\n",
    "\n",
    "model_cost = np.array([32 * d * (len(graph) + 15) for d in hyp])\n",
    "model_cost = (model_cost - np.min(model_cost)) / np.ptp(model_cost)\n",
    "\n",
    "error_array = np.array(error_list)\n",
    "\n",
    "for runs in range(error_array.shape[0]):\n",
    "    for cat in range(error_array.shape[1]):\n",
    "        error_array[runs][cat] = ((error_array[runs][cat] - np.min(error_array[runs][cat])) / np.ptp(error_array[runs][cat])) + model_cost\n",
    "        \n",
    "error_mean = np.mean(np.array(error_array), axis = 0)\n",
    "error_std = np.std(np.array(error_array), axis = 0) / np.sqrt(np.array(error_array).shape[0])\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x = list(hyp.keys()), \n",
    "                         y = error_mean[1, :], \n",
    "                         error_y = dict(type = 'data', \n",
    "                                        array = error_std[1, :]),\n",
    "                         name = 'SDNE+', \n",
    "                         mode = 'markers'))\n",
    "\n",
    "fig.update_layout(title_text = 'Model Selection - SDNE', \n",
    "                  xaxis_title_text = '# Dimensions (log scale)', \n",
    "                  yaxis_title_text = 'Description Length', \n",
    "                  font = dict(size = 18))\n",
    "fig.update_xaxes(type = 'log')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x = list(hyp.keys()), \n",
    "                         y = nuc_mean[1, :], \n",
    "                         error_y = dict(type = 'data', \n",
    "                                        array = nuc_std[1, :]),\n",
    "                         name = 'SDNE+', \n",
    "                         mode = 'markers'))\n",
    "fig.add_trace(go.Scatter(x = list(hyp.keys()), \n",
    "                         y = nuc_mean[0, :],\n",
    "                         error_y = dict(type = 'data', \n",
    "                                        array = nuc_std[0, :]),\n",
    "                         name = 'SDNE', \n",
    "                         mode = 'markers'))\n",
    "fig.update_layout(title_text = 'Nuclear Norm', \n",
    "                  xaxis_title_text = '# Dimensions (log scale)', \n",
    "                  yaxis_title_text = 'Normalized Nuclear Norm', \n",
    "                  font = dict(size = 18))\n",
    "fig.update_xaxes(type = 'log')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e88f76",
   "metadata": {},
   "source": [
    "### LINE vs LINE+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cfa98",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./email.pkl', 'rb') as file: \n",
    "    graph_dict = pkl.load(file)\n",
    "    \n",
    "graph = nx.Graph(nx.to_numpy_array(graph_dict['graph']))    \n",
    "graph = nx.Graph(nx.to_numpy_array(graph_dict))\n",
    "\n",
    "\n",
    "sense_feat_dict, sense_features = get_sense_features(graph, ppr_flag = 'std')\n",
    "\n",
    "hyp = line_email_hyp\n",
    "\n",
    "nuc_list = []\n",
    "error_list = []\n",
    "\n",
    "for run_idx in tqdm(range(40)):\n",
    "\n",
    "    models = {x : {} for x in hyp}\n",
    "    models_p_init = {x : {} for x in hyp}\n",
    "    \n",
    "\n",
    "\n",
    "    for d in tqdm(hyp):\n",
    "        line = LINE(graph, \n",
    "                embedding_size = d,\n",
    "                sense_features = sense_features,\n",
    "                alpha = hyp[d]['line']['alpha'], \n",
    "                ortho = hyp[d]['line']['ortho'], \n",
    "                sparse = hyp[d]['line']['sparse'],\n",
    "                learning_rate =  hyp[d]['line']['lr'],\n",
    "                order = 'second', \n",
    "                batch_size = len(graph))\n",
    "\n",
    "        history = line.train(epochs = 50)\n",
    "\n",
    "        e = line.get_embeddings()\n",
    "        embed_og = np.array([e[node_name] for node_name in graph.nodes()])\n",
    "        embed_og = (embed_og - np.min(embed_og)) / np.ptp(embed_og)\n",
    "\n",
    "\n",
    "        feature_dict_og = find_feature_membership(input_embed = embed_og,\n",
    "                                                            embed_name = 'LINE',\n",
    "                                                            sense_features = sense_features,\n",
    "                                                            sense_feat_dict = sense_feat_dict,\n",
    "                                                            top_k = 8,\n",
    "                                                            solver = 'nmf')\n",
    "\n",
    "        explain_og = feature_dict_og['explain_norm']\n",
    "        error_og = sense_features * np.log((sense_features + 1e-10) / ((embed_og @ feature_dict_og['explain_norm']) + 1e-10)) - sense_features + (embed_og @ feature_dict_og['explain_norm'])\n",
    "\n",
    "        explain_og = (explain_og - np.min(explain_og)) / np.ptp(explain_og)\n",
    "        \n",
    "        models[d]['e_norm_nuc'] = np.linalg.norm(explain_og, ord = 'nuc')\n",
    "        models[d]['e_norm_l1'] = np.linalg.norm(explain_og, ord = 1)\n",
    "        models[d]['e_norm_l2'] = np.linalg.norm(explain_og, ord = 2)\n",
    "        models[d]['entropy'] = np.std(explain_og, axis = 1)\n",
    "        models[d]['error'] = np.sum(error_og)\n",
    "\n",
    "\n",
    "        line_plus_init = LINE(graph, \n",
    "                        embedding_size = d,\n",
    "                        sense_features = sense_features, \n",
    "                        alpha = hyp[d]['line+ init']['alpha'], \n",
    "                        ortho = hyp[d]['line+ init']['ortho'], \n",
    "                        sparse = hyp[d]['line+ init']['sparse'],\n",
    "                        learning_rate =  hyp[d]['line+ init']['lr'],\n",
    "                        order = 'second', \n",
    "                        batch_size = len(graph))\n",
    "\n",
    "        line_plus_init.model.set_weights(line.model.get_weights())\n",
    "        history = line_plus_init.train(epochs = hyp[d]['line+ init']['epochs'])\n",
    "        \n",
    "        e = line_plus_init.get_embeddings()\n",
    "        embed_plus_init = np.array([e[node_name] for node_name in graph.nodes()])\n",
    "        embed_plus_init = (embed_plus_init - np.min(embed_plus_init)) / np.ptp(embed_plus_init)\n",
    "        \n",
    "\n",
    "        feature_dict_plus_init = find_feature_membership(input_embed = embed_plus_init,\n",
    "                                                            embed_name = 'LINE+ Init',\n",
    "                                                            sense_features = sense_features,\n",
    "                                                            sense_feat_dict = sense_feat_dict,\n",
    "                                                            top_k = 8,\n",
    "                                                            solver = 'nmf')\n",
    "\n",
    "        explain_plus_init = feature_dict_plus_init['explain_norm']\n",
    "        error_plus_init = sense_features * np.log((sense_features + 1e-10) / ((embed_plus_init @ feature_dict_plus_init['explain_norm']) + 1e-10)) - sense_features + (embed_plus_init @ feature_dict_plus_init['explain_norm'])\n",
    "\n",
    "        explain_plus_init = (explain_plus_init - np.min(explain_plus_init)) / np.ptp(explain_plus_init)\n",
    "        \n",
    "        models_p_init[d]['e_norm_nuc'] = np.linalg.norm(explain_plus_init, ord = 'nuc')\n",
    "        models_p_init[d]['e_norm_l1'] = np.linalg.norm(explain_plus_init, ord = 1)\n",
    "        models_p_init[d]['e_norm_l2'] = np.linalg.norm(explain_plus_init, ord = 2)\n",
    "        models_p_init[d]['entropy'] = np.std(explain_plus_init, axis = 1)\n",
    "        models_p_init[d]['error'] = np.sum(error_plus_init)\n",
    "\n",
    "        del line\n",
    "        del line_plus_init\n",
    "        \n",
    "        \n",
    "        \n",
    "    nuc_norm = np.array([[models[d]['e_norm_nuc'] for d in hyp], \n",
    "                        [models_p_init[d]['e_norm_nuc'] for d in hyp]])\n",
    "    \n",
    "    error = np.array([[models[d]['error'] for d in hyp], \n",
    "                        [models_p_init[d]['error'] for d in hyp],]) \n",
    "\n",
    "    \n",
    "    nuc_list.append(nuc_norm)\n",
    "    error_list.append(error)\n",
    "\n",
    "    \n",
    "    with open('./email_runs_40_line.pkl', 'wb') as file:\n",
    "        pkl.dump([nuc_list, error_list], file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9531ffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nuc_mean = np.mean(np.array(nuc_list), axis = 0)\n",
    "nuc_std = np.std(np.array(nuc_list), axis = 0) / np.sqrt(np.array(nuc_list).shape[0])\n",
    "\n",
    "model_cost = np.array([32 * d * (len(graph) + 15) for d in hyp])\n",
    "model_cost = (model_cost - np.min(model_cost)) / np.ptp(model_cost)\n",
    "\n",
    "error_array = np.array(error_list)\n",
    "\n",
    "for runs in range(error_array.shape[0]):\n",
    "    for cat in range(error_array.shape[1]):\n",
    "        error_array[runs][cat] = ((error_array[runs][cat] - np.min(error_array[runs][cat])) / np.ptp(error_array[runs][cat])) + model_cost\n",
    "        \n",
    "error_mean = np.mean(np.array(error_array), axis = 0)\n",
    "error_std = np.std(np.array(error_array), axis = 0) / np.sqrt(np.array(error_array).shape[0])\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x = list(hyp.keys()), \n",
    "                         y = error_mean[1, :], \n",
    "                         error_y = dict(type = 'data', \n",
    "                                        array = error_std[1, :]),\n",
    "                         name = 'LINE+', \n",
    "                         mode = 'markers'))\n",
    "\n",
    "fig.update_layout(title_text = 'Model Selection - LINE', \n",
    "                  xaxis_title_text = '# Dimensions (log scale)', \n",
    "                  yaxis_title_text = 'Description Length', \n",
    "                  font = dict(size = 18))\n",
    "fig.update_xaxes(type = 'log')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "\n",
    "fig.add_trace(go.Scatter(x = list(hyp.keys()), \n",
    "                         y = nuc_mean[1, :], \n",
    "                         error_y = dict(type = 'data', \n",
    "                                        array = nuc_std[1, :]),\n",
    "                         name = 'LINE+', \n",
    "                         mode = 'markers'))\n",
    "fig.add_trace(go.Scatter(x = list(hyp.keys()), \n",
    "                         y = nuc_mean[0, :],\n",
    "                         error_y = dict(type = 'data', \n",
    "                                        array = nuc_std[0, :]),\n",
    "                         name = 'LINE', \n",
    "                         mode = 'markers'))\n",
    "fig.update_layout(title_text = 'Nuclear Norm', \n",
    "                  xaxis_title_text = '# Dimensions (log scale)', \n",
    "                  yaxis_title_text = 'Normalized Nuclear Norm', \n",
    "                  font = dict(size = 18))\n",
    "fig.update_xaxes(type = 'log')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907e9d44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
